{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8dd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans#Clustering\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9045c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 1780722 nodes and 7550015 edges\n"
     ]
    }
   ],
   "source": [
    "train_graph=nx.read_edgelist('D:/Python Assignmment/Facebook Freind Reommendation/data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "print(nx.info(train_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f3e75",
   "metadata": {},
   "source": [
    "# Jaccard Distance:\n",
    "http://www.statisticshowto.com/jaccard-index/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba936957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for followees\n",
    "def jaccard_for_followees(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
    "    except:\n",
    "        return 0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25723be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#node 1635354 not in graph \n",
    "print(jaccard_for_followees(2730,1505))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304dc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for followers\n",
    "def jaccard_for_followers(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(g.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                 (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c4d298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#node 1635354 not in graph \n",
    "print(jaccard_for_followees(669354,1635354))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c53e2",
   "metadata": {},
   "source": [
    "## Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28b1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for followees\n",
    "def cosine_for_followees(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f6c9d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08944271909999159\n"
     ]
    }
   ],
   "source": [
    "print(cosine_for_followees(2,470294))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721efcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_for_followers(a,b):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "366f4b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02886751345948129\n"
     ]
    }
   ],
   "source": [
    "print(cosine_for_followers(2,470294))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb0c2a",
   "metadata": {},
   "source": [
    "## Ranking Measures\n",
    "https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea59c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(train_graph, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819721b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 1.6556497245737814e-07\n",
      "max 2.709825134193587e-05\n",
      "mean 5.615699699389075e-07\n"
     ]
    }
   ],
   "source": [
    "print('min',pr[min(pr, key=pr.get)])\n",
    "print('max',pr[max(pr, key=pr.get)])\n",
    "print('mean',float(sum(pr.values())) / len(pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e6c080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.615699699389075e-07\n"
     ]
    }
   ],
   "source": [
    "#for imputing to nodes which are not there in Train data\n",
    "mean_pr = float(sum(pr.values())) / len(pr)\n",
    "print(mean_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de74ab",
   "metadata": {},
   "source": [
    "## Shortest path:\n",
    "Getting Shortest path between twoo nodes, if nodes have direct path i.e directly connected then we are removing that edge and calculating path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521665bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if has direct edge then deleting that edge and calculating shortest path\n",
    "def compute_shortest_path_length(a,b):\n",
    "    p=-1\n",
    "    try:\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c30643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_shortest_path_length(77697, 826021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8252be",
   "metadata": {},
   "source": [
    "- A Strongly connected component is a sub-graph where there is a path from every node to every other node\n",
    "- A weakly connected component is one in which all components are connected by some path, ignoring direction. So this entire graph would be a weakly connected component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79811dde",
   "metadata": {},
   "source": [
    "## Checking for same community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96cd6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting weekly connected edges from graph \n",
    "wcc=list(nx.weakly_connected_components(train_graph))\n",
    "def belongs_to_same_wcc(a,b):\n",
    "    index = []\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    if train_graph.has_edge(a,b):\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if (b in index):\n",
    "                train_graph.remove_edge(a,b)\n",
    "                if compute_shortest_path_length(a,b)==-1:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 0\n",
    "                else:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if(b in index):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf3936d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belongs_to_same_wcc(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4c39bb",
   "metadata": {},
   "source": [
    "## Adamic/Adar Index:\n",
    "Adamic/Adar measures is defined as inverted sum of degrees of common neighbours for given two vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e29012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_adar_in(a,b):\n",
    "    sum=0\n",
    "    try:\n",
    "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0d9e6",
   "metadata": {},
   "source": [
    "## Does the person was follow back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44aed8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def follows_back(a,b):\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30306ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follows_back(1,189226)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c76e96",
   "metadata": {},
   "source": [
    "## Katz Centrality:\n",
    "https://en.wikipedia.org/wiki/Katz_centrality\n",
    "\n",
    "https://www.geeksforgeeks.org/katz-centrality-centrality-measure/ Katz centrality computes the centrality for a node based on the centrality of its neighbors. It is a generalization of the eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b392ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b82b35d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0007313532484065916\n",
      "max 0.003394554981699122\n",
      "mean 0.0007483800935562018\n"
     ]
    }
   ],
   "source": [
    "print('min',katz[min(katz, key=katz.get)])\n",
    "print('max',katz[max(katz, key=katz.get)])\n",
    "print('mean',float(sum(katz.values())) / len(katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f43cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007483800935562018\n"
     ]
    }
   ],
   "source": [
    "mean_katz = float(sum(katz.values())) / len(katz)\n",
    "print(mean_katz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780147fc",
   "metadata": {},
   "source": [
    "## Hits Score\n",
    "The HITS algorithm computes two numbers for a node. Authorities estimates the node value based on the incoming links. Hubs estimates the node value based on outgoing links.\n",
    "\n",
    "https://en.wikipedia.org/wiki/HITS_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7ae0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98446932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN -1.4376114543634408e-21\n",
      "MAX 0.004868653379538979\n",
      "MEAN 5.615699699308675e-07\n"
     ]
    }
   ],
   "source": [
    "print('MIN',hits[0][min(hits[0], key=hits[0].get)])\n",
    "print('MAX',hits[0][max(hits[0], key=hits[0].get)])\n",
    "print('MEAN',float(sum(hits[0].values())) / len(hits[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ff606",
   "metadata": {},
   "source": [
    "## Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed56136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "if not os.path.isfile('train_after_eda.csv'):\n",
    "    filename = \"train_after_eda.csv\"\n",
    "    # you uncomment this line, if you dont know the lentgh of the file name\n",
    "    # here we have hardcoded the number of lines as 15100030\n",
    "    # n_train = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
    "    n_train =  15100028\n",
    "    s = 100000 #desired sample size\n",
    "    skip_train = sorted(random.sample(range(1,n_train+1),n_train-s))\n",
    "    #https://stackoverflow.com/a/22259008/4084039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2d69c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('test_after_eda.csv'):\n",
    "    filename = \"test_after_eda.csv\"\n",
    "    # you uncomment this line, if you dont know the lentgh of the file name\n",
    "    # here we have hardcoded the number of lines as 3775008\n",
    "    # n_test = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
    "    n_test = 3775006\n",
    "    s = 50000 #desired sample size\n",
    "    skip_test = sorted(random.sample(range(1,n_test+1),n_test-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d280d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the train data file: 15100028\n",
      "Number of rows we are going to elimiate in train data are 15000028\n",
      "Number of rows in the test data file: 3775006\n",
      "Number of rows we are going to elimiate in test data are 3725006\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the train data file:\", n_train)\n",
    "print(\"Number of rows we are going to elimiate in train data are\",len(skip_train))\n",
    "print(\"Number of rows in the test data file:\", n_test)\n",
    "print(\"Number of rows we are going to elimiate in test data are\",len(skip_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61d2a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train matrix size  (100002, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273084</td>\n",
       "      <td>1505602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1553030</td>\n",
       "      <td>1283053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1622310</td>\n",
       "      <td>1645746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753961</td>\n",
       "      <td>1843752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785326</td>\n",
       "      <td>1006657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link\n",
       "0       273084           1505602               1\n",
       "1      1553030           1283053               1\n",
       "2      1622310           1645746               1\n",
       "3       753961           1843752               1\n",
       "4       785326           1006657               1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train = pd.read_csv('D:/Python Assignmment/Facebook Freind Reommendation/data/after_eda/train_after_eda.csv', skiprows=skip_train, names=['source_node', 'destination_node'])\n",
    "df_final_train['indicator_link'] = pd.read_csv('D:/Python Assignmment/Facebook Freind Reommendation/data/train_y.csv', skiprows=skip_train, names=['indicator_link'])\n",
    "print(\"Our train matrix size \",df_final_train.shape)\n",
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f5c9676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test matrix size  (50002, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848424</td>\n",
       "      <td>784690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>992327</td>\n",
       "      <td>550492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1810977</td>\n",
       "      <td>1642326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62624</td>\n",
       "      <td>262316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703183</td>\n",
       "      <td>1755993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link\n",
       "0       848424            784690               1\n",
       "1       992327            550492               1\n",
       "2      1810977           1642326               1\n",
       "3        62624            262316               1\n",
       "4      1703183           1755993               1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test = pd.read_csv('D:/Python Assignmment/Facebook Freind Reommendation/data/after_eda/test_after_eda.csv', skiprows=skip_test, names=['source_node', 'destination_node'])\n",
    "df_final_test['indicator_link'] = pd.read_csv('D:/Python Assignmment/Facebook Freind Reommendation/data/test_y.csv', skiprows=skip_test, names=['indicator_link'])\n",
    "print(\"Our test matrix size \",df_final_test.shape)\n",
    "df_final_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e721b",
   "metadata": {},
   "source": [
    "## Adding a set of features\n",
    "\n",
    "#### we will create these each of these features for both train and test data points\n",
    "\n",
    "- jaccard_followers\n",
    "- jaccard_followees\n",
    "- cosine_followers\n",
    "- cosine_followees\n",
    "- num_followers_s\n",
    "- num_followees_s\n",
    "- num_followers_d\n",
    "- num_followees_d\n",
    "- inter_followers\n",
    "- inter_followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e86fc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping jaccrd followers to train and test data\n",
    "df_final_train['jaccard_followers'] = df_final_train.apply(lambda row:jaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "df_final_test['jaccard_followers'] = df_final_test.apply(lambda row:jaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "#mapping jaccrd followees to train and test data\n",
    "df_final_train['jaccard_followees'] = df_final_train.apply(lambda row:jaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "df_final_test['jaccard_followees'] = df_final_test.apply(lambda row:jaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "#mapping jaccrd followers to train and test data\n",
    "df_final_train['cosine_followers'] = df_final_train.apply(lambda row:cosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "df_final_test['cosine_followers'] = df_final_test.apply(lambda row:cosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "#mapping jaccrd followees to train and test data\n",
    "df_final_train['cosine_followees'] = df_final_train.apply(lambda row:cosine_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "df_final_test['cosine_followees'] = df_final_test.apply(lambda row:cosine_for_followees(row['source_node'],row['destination_node']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c981d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating no of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    for i,row in df_final.iterrows():\n",
    "        try:\n",
    "            s1=set(train_graph.predecessors(row['source_node']))\n",
    "            s2=set(train_graph.successors(row['source_node']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1=set(train_graph.predecessors(row['destination_node']))\n",
    "            d2=set(train_graph.successors(row['destination_node']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0365f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train['num_followers_s'], df_final_train['num_followers_d'],df_final_train['num_followees_s'], df_final_train['num_followees_d'],df_final_train['inter_followers'], df_final_train['inter_followees']= compute_features_stage1(df_final_train)\n",
    "    \n",
    "df_final_test['num_followers_s'], df_final_test['num_followers_d'], df_final_test['num_followees_s'], df_final_test['num_followees_d'], df_final_test['inter_followers'], df_final_test['inter_followees']= compute_features_stage1(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "978fcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping adar index on train\n",
    "df_final_train['adar_index'] = df_final_train.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
    "#mapping adar index on test\n",
    "df_final_test['adar_index'] = df_final_test.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
    "#mapping followback or not on train\n",
    "df_final_train['follows_back'] = df_final_train.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "#mapping followback or not on test\n",
    "df_final_test['follows_back'] = df_final_test.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "\n",
    "#mapping same component of wcc or not on train\n",
    "df_final_train['same_comp'] = df_final_train.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "##mapping same component of wcc or not on train\n",
    "df_final_test['same_comp'] = df_final_test.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "#mapping shortest path on train \n",
    "df_final_train['shortest_path'] = df_final_train.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
    "#mapping shortest path on test\n",
    "df_final_test['shortest_path'] = df_final_test.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3c469",
   "metadata": {},
   "source": [
    "## Adding new set of features\n",
    "we will create these each of these features for both train and test data points\n",
    "\n",
    "## Weight Features\n",
    "- weight of incoming edges\n",
    "- weight of outgoing edges\n",
    "- weight of incoming edges + weight of outgoing edges\n",
    "- weight of incoming edges * weight of outgoing edges\n",
    "- 2*weight of incoming edges + weight of outgoing edges\n",
    "- weight of incoming edges + 2*weight of outgoing edges\n",
    "- Page Ranking of source\n",
    "- Page Ranking of dest\n",
    "- katz of source\n",
    "- katz of dest\n",
    "- hubs of source\n",
    "- hubs of dest\n",
    "- authorities_s of source\n",
    "- authorities_s of dest\n",
    "\n",
    "## Weight Features\n",
    "In order to determine the similarity of nodes, an edge weight value was calculated between nodes. Edge weight decreases as the neighbor count goes up. Intuitively, consider one million people following a celebrity on a social network then chances are most of them never met each other or the celebrity. On the other hand, if a user has 30 contacts in his/her social network, the chances are higher that many of them know each other. credit - Graph-based Features for Supervised Link Prediction William Cukierski, Benjamin Hamner, Bo Yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5087f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1780722/1780722 [00:12<00:00, 138786.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#weight for source and destination of each link\n",
    "Weight_in = {}\n",
    "Weight_out = {}\n",
    "for i in  tqdm(train_graph.nodes()):\n",
    "    s1=set(train_graph.predecessors(i))\n",
    "    w_in = 1.0/(np.sqrt(1+len(s1)))\n",
    "    Weight_in[i]=w_in\n",
    "    \n",
    "    s2=set(train_graph.successors(i))\n",
    "    w_out = 1.0/(np.sqrt(1+len(s2)))\n",
    "    Weight_out[i]=w_out\n",
    "    \n",
    "#for imputing with mean\n",
    "mean_weight_in = np.mean(list(Weight_in.values()))\n",
    "mean_weight_out = np.mean(list(Weight_out.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e66a7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train['weight_in'] = df_final_train.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "df_final_train['weight_out'] = df_final_train.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "#mapping to pandas test\n",
    "df_final_test['weight_in'] = df_final_test.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "df_final_test['weight_out'] = df_final_test.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "#some features engineerings on the in and out weights\n",
    "df_final_train['weight_f1'] = df_final_train.weight_in + df_final_train.weight_out\n",
    "df_final_train['weight_f2'] = df_final_train.weight_in * df_final_train.weight_out\n",
    "df_final_train['weight_f3'] = (2*df_final_train.weight_in + 1*df_final_train.weight_out)\n",
    "df_final_train['weight_f4'] = (1*df_final_train.weight_in + 2*df_final_train.weight_out)\n",
    "\n",
    "#some features engineerings on the in and out weights\n",
    "df_final_test['weight_f1'] = df_final_test.weight_in + df_final_test.weight_out\n",
    "df_final_test['weight_f2'] = df_final_test.weight_in * df_final_test.weight_out\n",
    "df_final_test['weight_f3'] = (2*df_final_test.weight_in + 1*df_final_test.weight_out)\n",
    "df_final_test['weight_f4'] = (1*df_final_test.weight_in + 2*df_final_test.weight_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "608944d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page rank for source and destination in Train and Test\n",
    "#if anything not there in train graph then adding mean page rank \n",
    "df_final_train['page_rank_s'] = df_final_train.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "df_final_train['page_rank_d'] = df_final_train.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "\n",
    "df_final_test['page_rank_s'] = df_final_test.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "df_final_test['page_rank_d'] = df_final_test.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "\n",
    "#Katz centrality score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding mean katz score\n",
    "df_final_train['katz_s'] = df_final_train.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "df_final_train['katz_d'] = df_final_train.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "\n",
    "df_final_test['katz_s'] = df_final_test.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "df_final_test['katz_d'] = df_final_test.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "#Hits algorithm score for source and destination in Train and test\n",
    "#if anything not there in train graph then adding 0\n",
    "df_final_train['hubs_s'] = df_final_train.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "df_final_train['hubs_d'] = df_final_train.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "\n",
    "df_final_test['hubs_s'] = df_final_test.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "df_final_test['hubs_d'] = df_final_test.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "#Hits algorithm score for source and destination in Train and Test\n",
    "#if anything not there in train graph then adding 0\n",
    "df_final_train['authorities_s'] = df_final_train.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "df_final_train['authorities_d'] = df_final_train.destination_node.apply(lambda x: hits[1].get(x,0))\n",
    "\n",
    "df_final_test['authorities_s'] = df_final_test.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "df_final_test['authorities_d'] = df_final_test.destination_node.apply(lambda x: hits[1].get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa509eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_f3</th>\n",
       "      <th>weight_f4</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>page_rank_d</th>\n",
       "      <th>katz_s</th>\n",
       "      <th>katz_d</th>\n",
       "      <th>hubs_s</th>\n",
       "      <th>hubs_d</th>\n",
       "      <th>authorities_s</th>\n",
       "      <th>authorities_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273084</td>\n",
       "      <td>1505602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005929</td>\n",
       "      <td>0.877964</td>\n",
       "      <td>2.045290e-06</td>\n",
       "      <td>3.459963e-07</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>1.943132e-13</td>\n",
       "      <td>1.941103e-13</td>\n",
       "      <td>9.226340e-16</td>\n",
       "      <td>2.231877e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1553030</td>\n",
       "      <td>1283053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.577350</td>\n",
       "      <td>1.654701</td>\n",
       "      <td>1.920836e-07</td>\n",
       "      <td>7.383663e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>2.972401e-18</td>\n",
       "      <td>6.024142e-19</td>\n",
       "      <td>3.151929e-17</td>\n",
       "      <td>3.035046e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1622310</td>\n",
       "      <td>1645746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.590990</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.770036e-06</td>\n",
       "      <td>4.191489e-07</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>2.437843e-13</td>\n",
       "      <td>8.329992e-15</td>\n",
       "      <td>1.154664e-12</td>\n",
       "      <td>1.714436e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753961</td>\n",
       "      <td>1843752</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.042322e-07</td>\n",
       "      <td>6.428994e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>3.077892e-25</td>\n",
       "      <td>4.764690e-18</td>\n",
       "      <td>3.346100e-20</td>\n",
       "      <td>4.288164e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785326</td>\n",
       "      <td>1006657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029697</td>\n",
       "      <td>0.834650</td>\n",
       "      <td>1.175733e-06</td>\n",
       "      <td>3.858586e-07</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>2.457399e-15</td>\n",
       "      <td>2.946429e-16</td>\n",
       "      <td>4.455638e-15</td>\n",
       "      <td>1.391225e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link  jaccard_followers  \\\n",
       "0       273084           1505602               1                  0   \n",
       "1      1553030           1283053               1                  0   \n",
       "2      1622310           1645746               1                  0   \n",
       "3       753961           1843752               1                  0   \n",
       "4       785326           1006657               1                  0   \n",
       "\n",
       "   jaccard_followees  cosine_followers  cosine_followees  num_followers_s  \\\n",
       "0                0.0               0.0               0.0               11   \n",
       "1                0.0               0.0               0.0                1   \n",
       "2                0.0               0.0               0.0               23   \n",
       "3                0.0               0.0               0.0                1   \n",
       "4                0.0               0.0               0.0               14   \n",
       "\n",
       "   num_followers_d  num_followees_s  ...  weight_f3  weight_f4   page_rank_s  \\\n",
       "0                6               15  ...   1.005929   0.877964  2.045290e-06   \n",
       "1                3                2  ...   1.577350   1.654701  1.920836e-07   \n",
       "2                2               32  ...   1.590990   1.060660  1.770036e-06   \n",
       "3                1                1  ...   3.000000   3.000000  4.042322e-07   \n",
       "4                5               21  ...   1.029697   0.834650  1.175733e-06   \n",
       "\n",
       "    page_rank_d    katz_s    katz_d        hubs_s        hubs_d  \\\n",
       "0  3.459963e-07  0.000773  0.000756  1.943132e-13  1.941103e-13   \n",
       "1  7.383663e-07  0.000735  0.000742  2.972401e-18  6.024142e-19   \n",
       "2  4.191489e-07  0.000822  0.000739  2.437843e-13  8.329992e-15   \n",
       "3  6.428994e-07  0.000735  0.000735  3.077892e-25  4.764690e-18   \n",
       "4  3.858586e-07  0.000787  0.000751  2.457399e-15  2.946429e-16   \n",
       "\n",
       "   authorities_s  authorities_d  \n",
       "0   9.226340e-16   2.231877e-15  \n",
       "1   3.151929e-17   3.035046e-19  \n",
       "2   1.154664e-12   1.714436e-15  \n",
       "3   3.346100e-20   4.288164e-23  \n",
       "4   4.455638e-15   1.391225e-15  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210950b",
   "metadata": {},
   "source": [
    "http://be.amazd.com/link-prediction/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e5b0d",
   "metadata": {},
   "source": [
    "## Preferential Attachment:\n",
    "One well-known concept in social networks is that users with many friends tend to create more connections in the future. This is due to the fact that in some social networks, like in finance, the rich get richer. We estimate how ”rich” our two vertices are by calculating the multiplication between the number of friends (|Γ(x)|) or followers each vertex has. It may be noted that the similarity index does not require any node neighbor information; therefore, this similarity index has the lowest computational complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "274768ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_attachment_followers(df): # function for calculating  preferential_attachment\n",
    "    preferential_attachment=[] \n",
    "    preferential_attachment=df['num_followers_s']*df['num_followers_d']\n",
    "    return preferential_attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a14d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train[' preferential_attachment_followers']=preferential_attachment_followers(df_final_train)\n",
    "df_final_test[' preferential_attachment_followers']=preferential_attachment_followers(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ed0066f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>...</th>\n",
       "      <th>weight_f4</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>page_rank_d</th>\n",
       "      <th>katz_s</th>\n",
       "      <th>katz_d</th>\n",
       "      <th>hubs_s</th>\n",
       "      <th>hubs_d</th>\n",
       "      <th>authorities_s</th>\n",
       "      <th>authorities_d</th>\n",
       "      <th>preferential_attachment_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273084</td>\n",
       "      <td>1505602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877964</td>\n",
       "      <td>2.045290e-06</td>\n",
       "      <td>3.459963e-07</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>1.943132e-13</td>\n",
       "      <td>1.941103e-13</td>\n",
       "      <td>9.226340e-16</td>\n",
       "      <td>2.231877e-15</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1553030</td>\n",
       "      <td>1283053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654701</td>\n",
       "      <td>1.920836e-07</td>\n",
       "      <td>7.383663e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>2.972401e-18</td>\n",
       "      <td>6.024142e-19</td>\n",
       "      <td>3.151929e-17</td>\n",
       "      <td>3.035046e-19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1622310</td>\n",
       "      <td>1645746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.770036e-06</td>\n",
       "      <td>4.191489e-07</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>2.437843e-13</td>\n",
       "      <td>8.329992e-15</td>\n",
       "      <td>1.154664e-12</td>\n",
       "      <td>1.714436e-15</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753961</td>\n",
       "      <td>1843752</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.042322e-07</td>\n",
       "      <td>6.428994e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>3.077892e-25</td>\n",
       "      <td>4.764690e-18</td>\n",
       "      <td>3.346100e-20</td>\n",
       "      <td>4.288164e-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785326</td>\n",
       "      <td>1006657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834650</td>\n",
       "      <td>1.175733e-06</td>\n",
       "      <td>3.858586e-07</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>2.457399e-15</td>\n",
       "      <td>2.946429e-16</td>\n",
       "      <td>4.455638e-15</td>\n",
       "      <td>1.391225e-15</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link  jaccard_followers  \\\n",
       "0       273084           1505602               1                  0   \n",
       "1      1553030           1283053               1                  0   \n",
       "2      1622310           1645746               1                  0   \n",
       "3       753961           1843752               1                  0   \n",
       "4       785326           1006657               1                  0   \n",
       "\n",
       "   jaccard_followees  cosine_followers  cosine_followees  num_followers_s  \\\n",
       "0                0.0               0.0               0.0               11   \n",
       "1                0.0               0.0               0.0                1   \n",
       "2                0.0               0.0               0.0               23   \n",
       "3                0.0               0.0               0.0                1   \n",
       "4                0.0               0.0               0.0               14   \n",
       "\n",
       "   num_followers_d  num_followees_s  ...  weight_f4   page_rank_s  \\\n",
       "0                6               15  ...   0.877964  2.045290e-06   \n",
       "1                3                2  ...   1.654701  1.920836e-07   \n",
       "2                2               32  ...   1.060660  1.770036e-06   \n",
       "3                1                1  ...   3.000000  4.042322e-07   \n",
       "4                5               21  ...   0.834650  1.175733e-06   \n",
       "\n",
       "    page_rank_d    katz_s    katz_d        hubs_s        hubs_d  \\\n",
       "0  3.459963e-07  0.000773  0.000756  1.943132e-13  1.941103e-13   \n",
       "1  7.383663e-07  0.000735  0.000742  2.972401e-18  6.024142e-19   \n",
       "2  4.191489e-07  0.000822  0.000739  2.437843e-13  8.329992e-15   \n",
       "3  6.428994e-07  0.000735  0.000735  3.077892e-25  4.764690e-18   \n",
       "4  3.858586e-07  0.000787  0.000751  2.457399e-15  2.946429e-16   \n",
       "\n",
       "   authorities_s  authorities_d   preferential_attachment_followers  \n",
       "0   9.226340e-16   2.231877e-15                                  66  \n",
       "1   3.151929e-17   3.035046e-19                                   3  \n",
       "2   1.154664e-12   1.714436e-15                                  46  \n",
       "3   3.346100e-20   4.288164e-23                                   1  \n",
       "4   4.455638e-15   1.391225e-15                                  70  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98a660b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_attachment_followees(df): # function for calculating  preferential_attachment\n",
    "    preferential_attachment=[] \n",
    "    preferential_attachment=df['num_followees_s']*df['num_followees_d']\n",
    "    return preferential_attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcf9b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train[' preferential_attachment_followees']=preferential_attachment_followees(df_final_train)\n",
    "df_final_test[' preferential_attachment_followees']=preferential_attachment_followees(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a1bcb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>...</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>page_rank_d</th>\n",
       "      <th>katz_s</th>\n",
       "      <th>katz_d</th>\n",
       "      <th>hubs_s</th>\n",
       "      <th>hubs_d</th>\n",
       "      <th>authorities_s</th>\n",
       "      <th>authorities_d</th>\n",
       "      <th>preferential_attachment_followers</th>\n",
       "      <th>preferential_attachment_followees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273084</td>\n",
       "      <td>1505602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2.045290e-06</td>\n",
       "      <td>3.459963e-07</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>1.943132e-13</td>\n",
       "      <td>1.941103e-13</td>\n",
       "      <td>9.226340e-16</td>\n",
       "      <td>2.231877e-15</td>\n",
       "      <td>66</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1553030</td>\n",
       "      <td>1283053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.920836e-07</td>\n",
       "      <td>7.383663e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>2.972401e-18</td>\n",
       "      <td>6.024142e-19</td>\n",
       "      <td>3.151929e-17</td>\n",
       "      <td>3.035046e-19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1622310</td>\n",
       "      <td>1645746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.770036e-06</td>\n",
       "      <td>4.191489e-07</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>2.437843e-13</td>\n",
       "      <td>8.329992e-15</td>\n",
       "      <td>1.154664e-12</td>\n",
       "      <td>1.714436e-15</td>\n",
       "      <td>46</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753961</td>\n",
       "      <td>1843752</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.042322e-07</td>\n",
       "      <td>6.428994e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>3.077892e-25</td>\n",
       "      <td>4.764690e-18</td>\n",
       "      <td>3.346100e-20</td>\n",
       "      <td>4.288164e-23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785326</td>\n",
       "      <td>1006657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175733e-06</td>\n",
       "      <td>3.858586e-07</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>2.457399e-15</td>\n",
       "      <td>2.946429e-16</td>\n",
       "      <td>4.455638e-15</td>\n",
       "      <td>1.391225e-15</td>\n",
       "      <td>70</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link  jaccard_followers  \\\n",
       "0       273084           1505602               1                  0   \n",
       "1      1553030           1283053               1                  0   \n",
       "2      1622310           1645746               1                  0   \n",
       "3       753961           1843752               1                  0   \n",
       "4       785326           1006657               1                  0   \n",
       "\n",
       "   jaccard_followees  cosine_followers  cosine_followees  num_followers_s  \\\n",
       "0                0.0               0.0               0.0               11   \n",
       "1                0.0               0.0               0.0                1   \n",
       "2                0.0               0.0               0.0               23   \n",
       "3                0.0               0.0               0.0                1   \n",
       "4                0.0               0.0               0.0               14   \n",
       "\n",
       "   num_followers_d  num_followees_s  ...   page_rank_s   page_rank_d  \\\n",
       "0                6               15  ...  2.045290e-06  3.459963e-07   \n",
       "1                3                2  ...  1.920836e-07  7.383663e-07   \n",
       "2                2               32  ...  1.770036e-06  4.191489e-07   \n",
       "3                1                1  ...  4.042322e-07  6.428994e-07   \n",
       "4                5               21  ...  1.175733e-06  3.858586e-07   \n",
       "\n",
       "     katz_s    katz_d        hubs_s        hubs_d  authorities_s  \\\n",
       "0  0.000773  0.000756  1.943132e-13  1.941103e-13   9.226340e-16   \n",
       "1  0.000735  0.000742  2.972401e-18  6.024142e-19   3.151929e-17   \n",
       "2  0.000822  0.000739  2.437843e-13  8.329992e-15   1.154664e-12   \n",
       "3  0.000735  0.000735  3.077892e-25  4.764690e-18   3.346100e-20   \n",
       "4  0.000787  0.000751  2.457399e-15  2.946429e-16   4.455638e-15   \n",
       "\n",
       "   authorities_d   preferential_attachment_followers  \\\n",
       "0   2.231877e-15                                  66   \n",
       "1   3.035046e-19                                   3   \n",
       "2   1.714436e-15                                  46   \n",
       "3   4.288164e-23                                   1   \n",
       "4   1.391225e-15                                  70   \n",
       "\n",
       "    preferential_attachment_followees  \n",
       "0                                 120  \n",
       "1                                   2  \n",
       "2                                  96  \n",
       "3                                   2  \n",
       "4                                 105  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbfe6552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>...</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>page_rank_d</th>\n",
       "      <th>katz_s</th>\n",
       "      <th>katz_d</th>\n",
       "      <th>hubs_s</th>\n",
       "      <th>hubs_d</th>\n",
       "      <th>authorities_s</th>\n",
       "      <th>authorities_d</th>\n",
       "      <th>preferential_attachment_followers</th>\n",
       "      <th>preferential_attachment_followees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848424</td>\n",
       "      <td>784690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.557971e-07</td>\n",
       "      <td>1.559547e-06</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>3.243237e-16</td>\n",
       "      <td>1.745624e-16</td>\n",
       "      <td>2.969838e-15</td>\n",
       "      <td>9.269209e-14</td>\n",
       "      <td>84</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>992327</td>\n",
       "      <td>550492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.082479</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188425e-06</td>\n",
       "      <td>1.546425e-06</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>4.565988e-20</td>\n",
       "      <td>7.406283e-18</td>\n",
       "      <td>2.312228e-22</td>\n",
       "      <td>6.494766e-19</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1810977</td>\n",
       "      <td>1642326</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>6.040773e-07</td>\n",
       "      <td>1.446579e-06</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>7.287984e-16</td>\n",
       "      <td>1.939912e-13</td>\n",
       "      <td>2.253291e-15</td>\n",
       "      <td>1.479773e-16</td>\n",
       "      <td>91</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62624</td>\n",
       "      <td>262316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.038490</td>\n",
       "      <td>0.140028</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.811548e-07</td>\n",
       "      <td>1.131541e-06</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>3.074607e-15</td>\n",
       "      <td>4.084766e-13</td>\n",
       "      <td>2.981043e-15</td>\n",
       "      <td>2.711831e-13</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703183</td>\n",
       "      <td>1755993</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.183879e-06</td>\n",
       "      <td>9.718901e-07</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>1.425711e-20</td>\n",
       "      <td>5.413715e-16</td>\n",
       "      <td>2.909971e-19</td>\n",
       "      <td>2.216786e-17</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link  jaccard_followers  \\\n",
       "0       848424            784690               1                  0   \n",
       "1       992327            550492               1                  0   \n",
       "2      1810977           1642326               1                  0   \n",
       "3        62624            262316               1                  0   \n",
       "4      1703183           1755993               1                  0   \n",
       "\n",
       "   jaccard_followees  cosine_followers  cosine_followees  num_followers_s  \\\n",
       "0           0.000000          0.029161          0.000000                6   \n",
       "1           0.222222          0.082479          0.377964                3   \n",
       "2           0.000000          0.000000          0.000000                7   \n",
       "3           0.052632          0.038490          0.140028                3   \n",
       "4           0.000000          0.055902          0.000000                5   \n",
       "\n",
       "   num_followers_d  num_followees_s  ...   page_rank_s   page_rank_d  \\\n",
       "0               14                6  ...  6.557971e-07  1.559547e-06   \n",
       "1                7                4  ...  1.188425e-06  1.546425e-06   \n",
       "2               13                9  ...  6.040773e-07  1.446579e-06   \n",
       "3               15                3  ...  2.811548e-07  1.131541e-06   \n",
       "4                8                2  ...  1.183879e-06  9.718901e-07   \n",
       "\n",
       "     katz_s    katz_d        hubs_s        hubs_d  authorities_s  \\\n",
       "0  0.000754  0.000786  3.243237e-16  1.745624e-16   2.969838e-15   \n",
       "1  0.000742  0.000757  4.565988e-20  7.406283e-18   2.312228e-22   \n",
       "2  0.000759  0.000781  7.287984e-16  1.939912e-13   2.253291e-15   \n",
       "3  0.000743  0.000790  3.074607e-15  4.084766e-13   2.981043e-15   \n",
       "4  0.000750  0.000762  1.425711e-20  5.413715e-16   2.909971e-19   \n",
       "\n",
       "   authorities_d   preferential_attachment_followers  \\\n",
       "0   9.269209e-14                                  84   \n",
       "1   6.494766e-19                                  21   \n",
       "2   1.479773e-16                                  91   \n",
       "3   2.711831e-13                                  45   \n",
       "4   2.216786e-17                                  40   \n",
       "\n",
       "    preferential_attachment_followees  \n",
       "0                                  54  \n",
       "1                                  28  \n",
       "2                                 108  \n",
       "3                                  51  \n",
       "4                                  22  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b5461",
   "metadata": {},
   "source": [
    "## Adding new set of features\n",
    "we will create these each of these features for both train and test data points\n",
    "\n",
    "SVD features for both source and destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25535af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(x, S):\n",
    "    try:\n",
    "        z = sadj_dict[x]\n",
    "        return S[z]\n",
    "    except:\n",
    "        return [0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c85dee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for svd features to get feature vector creating a dict node val and index in svd vector\n",
    "sadj_col = sorted(train_graph.nodes())\n",
    "sadj_dict = { val:idx for idx,val in enumerate(sadj_col)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd5a6dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780722"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sadj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e76ddb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj =nx.adjacency_matrix(train_graph,nodelist=sorted(train_graph.nodes())).asfptype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9900a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 180907)\t1.0\n",
      "  (0, 301965)\t1.0\n",
      "  (1, 598394)\t1.0\n",
      "  (1, 797643)\t1.0\n",
      "  (1, 919667)\t1.0\n",
      "  (1, 1142212)\t1.0\n",
      "  (1, 1545223)\t1.0\n",
      "  (2, 169215)\t1.0\n",
      "  (2, 266193)\t1.0\n",
      "  (2, 515484)\t1.0\n",
      "  (2, 1207861)\t1.0\n",
      "  (3, 5985)\t1.0\n",
      "  (3, 1777903)\t1.0\n",
      "  (5, 1507720)\t1.0\n",
      "  (6, 76841)\t1.0\n",
      "  (6, 743869)\t1.0\n",
      "  (6, 1683883)\t1.0\n",
      "  (8, 1585129)\t1.0\n",
      "  (9, 547335)\t1.0\n",
      "  (10, 436141)\t1.0\n",
      "  (10, 676815)\t1.0\n",
      "  (10, 1190123)\t1.0\n",
      "  (11, 27338)\t1.0\n",
      "  (11, 35691)\t1.0\n",
      "  (11, 196996)\t1.0\n",
      "  :\t:\n",
      "  (1780716, 963620)\t1.0\n",
      "  (1780716, 1115404)\t1.0\n",
      "  (1780716, 1188206)\t1.0\n",
      "  (1780717, 1425478)\t1.0\n",
      "  (1780718, 164758)\t1.0\n",
      "  (1780718, 1351893)\t1.0\n",
      "  (1780719, 37690)\t1.0\n",
      "  (1780719, 190746)\t1.0\n",
      "  (1780719, 214157)\t1.0\n",
      "  (1780719, 317913)\t1.0\n",
      "  (1780719, 952312)\t1.0\n",
      "  (1780719, 1030707)\t1.0\n",
      "  (1780719, 1380897)\t1.0\n",
      "  (1780719, 1402810)\t1.0\n",
      "  (1780719, 1679425)\t1.0\n",
      "  (1780719, 1740185)\t1.0\n",
      "  (1780719, 1769726)\t1.0\n",
      "  (1780720, 539001)\t1.0\n",
      "  (1780720, 998332)\t1.0\n",
      "  (1780720, 1028930)\t1.0\n",
      "  (1780720, 1100093)\t1.0\n",
      "  (1780720, 1135303)\t1.0\n",
      "  (1780720, 1557972)\t1.0\n",
      "  (1780720, 1749240)\t1.0\n",
      "  (1780721, 1672331)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(Adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2277879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix Shape (1780722, 1780722)\n",
      "U Shape (1780722, 6)\n",
      "V Shape (6, 1780722)\n",
      "s Shape (6,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds, eigs\n",
    "U, s, V = svds(Adj, k = 6)\n",
    "print('Adjacency matrix Shape',Adj.shape)\n",
    "print('U Shape',U.shape)\n",
    "print('V Shape',V.shape)\n",
    "print('s Shape',s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec4195b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] =df_final_train.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    \n",
    "df_final_train[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] =df_final_train.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "\n",
    "    \n",
    "df_final_train[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] =df_final_train.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "df_final_train[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] =df_final_train.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "\n",
    "    \n",
    "df_final_test[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] =df_final_test.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    \n",
    "df_final_test[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] =df_final_test.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "\n",
    "df_final_test[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] =df_final_test.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "\n",
    "df_final_test[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] =df_final_test.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7da2b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_node', 'destination_node', 'indicator_link',\n",
       "       'jaccard_followers', 'jaccard_followees', 'cosine_followers',\n",
       "       'cosine_followees', 'num_followers_s', 'num_followers_d',\n",
       "       'num_followees_s', 'num_followees_d', 'inter_followers',\n",
       "       'inter_followees', 'adar_index', 'follows_back', 'same_comp',\n",
       "       'shortest_path', 'weight_in', 'weight_out', 'weight_f1', 'weight_f2',\n",
       "       'weight_f3', 'weight_f4', 'page_rank_s', 'page_rank_d', 'katz_s',\n",
       "       'katz_d', 'hubs_s', 'hubs_d', 'authorities_s', 'authorities_d',\n",
       "       ' preferential_attachment_followers',\n",
       "       ' preferential_attachment_followees', 'svd_u_s_1', 'svd_u_s_2',\n",
       "       'svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6', 'svd_u_d_1',\n",
       "       'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5', 'svd_u_d_6',\n",
       "       'svd_v_s_1', 'svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5',\n",
       "       'svd_v_s_6', 'svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4',\n",
       "       'svd_v_d_5', 'svd_v_d_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fd1fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NP_dot_U(df):# function product between source node and destination of svd features\n",
    "    np_dot_u=[]\n",
    "    for i,row in df.iterrows():\n",
    "        a=svd(row['source_node'],U)\n",
    "        b=svd(row['destination_node'],U)\n",
    "        np_dot_u.append(np.dot(a,b))\n",
    "    return np_dot_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71f7321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train['np_dot_u']=NP_dot_U(df_final_train)\n",
    "df_final_test['np_dot_u']=NP_dot_U(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce8d6a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_v_s_4</th>\n",
       "      <th>svd_v_s_5</th>\n",
       "      <th>svd_v_s_6</th>\n",
       "      <th>svd_v_d_1</th>\n",
       "      <th>svd_v_d_2</th>\n",
       "      <th>svd_v_d_3</th>\n",
       "      <th>svd_v_d_4</th>\n",
       "      <th>svd_v_d_5</th>\n",
       "      <th>svd_v_d_6</th>\n",
       "      <th>np_dot_u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273084</td>\n",
       "      <td>1505602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.545081e-13</td>\n",
       "      <td>8.108427e-13</td>\n",
       "      <td>1.719693e-14</td>\n",
       "      <td>1.355366e-12</td>\n",
       "      <td>-4.675325e-13</td>\n",
       "      <td>1.128583e-06</td>\n",
       "      <td>-6.616643e-14</td>\n",
       "      <td>9.771064e-13</td>\n",
       "      <td>4.159933e-14</td>\n",
       "      <td>1.114915e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1553030</td>\n",
       "      <td>1283053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.148788e-13</td>\n",
       "      <td>2.190137e-13</td>\n",
       "      <td>5.874891e-16</td>\n",
       "      <td>4.845761e-16</td>\n",
       "      <td>-2.316073e-14</td>\n",
       "      <td>1.928105e-14</td>\n",
       "      <td>-6.759727e-16</td>\n",
       "      <td>7.030249e-15</td>\n",
       "      <td>5.657677e-18</td>\n",
       "      <td>1.094252e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1622310</td>\n",
       "      <td>1645746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.826493e-11</td>\n",
       "      <td>3.413958e-10</td>\n",
       "      <td>2.152186e-11</td>\n",
       "      <td>4.054264e-22</td>\n",
       "      <td>-1.792510e-22</td>\n",
       "      <td>3.411138e-22</td>\n",
       "      <td>-7.398857e-22</td>\n",
       "      <td>8.573778e-22</td>\n",
       "      <td>2.444712e-22</td>\n",
       "      <td>8.441613e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753961</td>\n",
       "      <td>1843752</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.953979e-19</td>\n",
       "      <td>4.480502e-19</td>\n",
       "      <td>6.242202e-19</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.066760e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785326</td>\n",
       "      <td>1006657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.872202e-12</td>\n",
       "      <td>1.093180e-12</td>\n",
       "      <td>8.304873e-14</td>\n",
       "      <td>4.145450e-13</td>\n",
       "      <td>-1.613517e-13</td>\n",
       "      <td>5.086368e-07</td>\n",
       "      <td>-2.528563e-14</td>\n",
       "      <td>1.320862e-13</td>\n",
       "      <td>2.593113e-14</td>\n",
       "      <td>7.539604e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link  jaccard_followers  \\\n",
       "0       273084           1505602               1                  0   \n",
       "1      1553030           1283053               1                  0   \n",
       "2      1622310           1645746               1                  0   \n",
       "3       753961           1843752               1                  0   \n",
       "4       785326           1006657               1                  0   \n",
       "\n",
       "   jaccard_followees  cosine_followers  cosine_followees  num_followers_s  \\\n",
       "0                0.0               0.0               0.0               11   \n",
       "1                0.0               0.0               0.0                1   \n",
       "2                0.0               0.0               0.0               23   \n",
       "3                0.0               0.0               0.0                1   \n",
       "4                0.0               0.0               0.0               14   \n",
       "\n",
       "   num_followers_d  num_followees_s  ...     svd_v_s_4     svd_v_s_5  \\\n",
       "0                6               15  ... -1.545081e-13  8.108427e-13   \n",
       "1                3                2  ... -2.148788e-13  2.190137e-13   \n",
       "2                2               32  ... -3.826493e-11  3.413958e-10   \n",
       "3                1                1  ... -1.953979e-19  4.480502e-19   \n",
       "4                5               21  ... -2.872202e-12  1.093180e-12   \n",
       "\n",
       "      svd_v_s_6     svd_v_d_1     svd_v_d_2     svd_v_d_3     svd_v_d_4  \\\n",
       "0  1.719693e-14  1.355366e-12 -4.675325e-13  1.128583e-06 -6.616643e-14   \n",
       "1  5.874891e-16  4.845761e-16 -2.316073e-14  1.928105e-14 -6.759727e-16   \n",
       "2  2.152186e-11  4.054264e-22 -1.792510e-22  3.411138e-22 -7.398857e-22   \n",
       "3  6.242202e-19  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4  8.304873e-14  4.145450e-13 -1.613517e-13  5.086368e-07 -2.528563e-14   \n",
       "\n",
       "      svd_v_d_5     svd_v_d_6      np_dot_u  \n",
       "0  9.771064e-13  4.159933e-14  1.114915e-11  \n",
       "1  7.030249e-15  5.657677e-18  1.094252e-25  \n",
       "2  8.573778e-22  2.444712e-22  8.441613e-18  \n",
       "3  0.000000e+00  0.000000e+00 -3.066760e-33  \n",
       "4  1.320862e-13  2.593113e-14  7.539604e-13  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3b919ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NP_dot_V(df):# function product between source node and destination of svd features\n",
    "    np_dot_v=[]\n",
    "    for i,row in df.iterrows():\n",
    "        a=svd(row['source_node'],V.T)\n",
    "        b=svd(row['destination_node'],V.T)\n",
    "        np_dot_v.append(np.dot(a,b))\n",
    "    return np_dot_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ba1f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train['np_dot_v']=NP_dot_V(df_final_train)\n",
    "df_final_test['np_dot_v']=NP_dot_V(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d9ec545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>num_followers_s</th>\n",
       "      <th>num_followers_d</th>\n",
       "      <th>num_followees_s</th>\n",
       "      <th>...</th>\n",
       "      <th>svd_v_s_5</th>\n",
       "      <th>svd_v_s_6</th>\n",
       "      <th>svd_v_d_1</th>\n",
       "      <th>svd_v_d_2</th>\n",
       "      <th>svd_v_d_3</th>\n",
       "      <th>svd_v_d_4</th>\n",
       "      <th>svd_v_d_5</th>\n",
       "      <th>svd_v_d_6</th>\n",
       "      <th>np_dot_u</th>\n",
       "      <th>np_dot_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273084</td>\n",
       "      <td>1505602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>8.108436e-13</td>\n",
       "      <td>1.719704e-14</td>\n",
       "      <td>1.355366e-12</td>\n",
       "      <td>-4.675315e-13</td>\n",
       "      <td>1.128586e-06</td>\n",
       "      <td>-6.616693e-14</td>\n",
       "      <td>9.771076e-13</td>\n",
       "      <td>4.160013e-14</td>\n",
       "      <td>1.114912e-11</td>\n",
       "      <td>2.238770e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>901833</td>\n",
       "      <td>1416532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2.172396e-14</td>\n",
       "      <td>4.145166e-05</td>\n",
       "      <td>4.864432e-16</td>\n",
       "      <td>-4.559207e-15</td>\n",
       "      <td>3.869427e-13</td>\n",
       "      <td>2.265956e-11</td>\n",
       "      <td>1.932551e-14</td>\n",
       "      <td>3.825880e-05</td>\n",
       "      <td>-6.409548e-24</td>\n",
       "      <td>1.585891e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>579094</td>\n",
       "      <td>110619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.034360</td>\n",
       "      <td>0.096225</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.126566e-12</td>\n",
       "      <td>4.582894e-16</td>\n",
       "      <td>3.142402e-15</td>\n",
       "      <td>-3.986460e-12</td>\n",
       "      <td>5.691485e-12</td>\n",
       "      <td>-1.722264e-12</td>\n",
       "      <td>9.646153e-14</td>\n",
       "      <td>6.396681e-15</td>\n",
       "      <td>2.001676e-21</td>\n",
       "      <td>9.833261e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1190643</td>\n",
       "      <td>212431</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631047e-13</td>\n",
       "      <td>3.719701e-14</td>\n",
       "      <td>2.008314e-13</td>\n",
       "      <td>-1.006827e-13</td>\n",
       "      <td>1.071665e-13</td>\n",
       "      <td>-6.309365e-15</td>\n",
       "      <td>3.790089e-15</td>\n",
       "      <td>3.383652e-16</td>\n",
       "      <td>1.127063e-25</td>\n",
       "      <td>6.977532e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99661</td>\n",
       "      <td>62265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161826</td>\n",
       "      <td>0.027517</td>\n",
       "      <td>0.288265</td>\n",
       "      <td>62</td>\n",
       "      <td>240</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.413968e-13</td>\n",
       "      <td>2.279508e-02</td>\n",
       "      <td>-1.319163e-13</td>\n",
       "      <td>6.676304e-13</td>\n",
       "      <td>-3.305846e-10</td>\n",
       "      <td>1.529819e-08</td>\n",
       "      <td>-3.385254e-12</td>\n",
       "      <td>9.355920e-02</td>\n",
       "      <td>2.911225e-03</td>\n",
       "      <td>2.132690e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link  jaccard_followers  \\\n",
       "0       273084           1505602               1                  0   \n",
       "1       901833           1416532               1                  0   \n",
       "2       579094            110619               1                  0   \n",
       "3      1190643            212431               1                  0   \n",
       "4        99661             62265               1                  0   \n",
       "\n",
       "   jaccard_followees  cosine_followers  cosine_followees  num_followers_s  \\\n",
       "0           0.000000          0.000000          0.000000               11   \n",
       "1           0.000000          0.125000          0.000000               36   \n",
       "2           0.050000          0.034360          0.096225                7   \n",
       "3           0.000000          0.000000          0.000000                6   \n",
       "4           0.161826          0.027517          0.288265               62   \n",
       "\n",
       "   num_followers_d  num_followees_s  ...     svd_v_s_5     svd_v_s_6  \\\n",
       "0                6               15  ...  8.108436e-13  1.719704e-14   \n",
       "1               32               40  ...  2.172396e-14  4.145166e-05   \n",
       "2               11                9  ...  1.126566e-12  4.582894e-16   \n",
       "3                8                3  ...  1.631047e-13  3.719701e-14   \n",
       "4              240              104  ... -8.413968e-13  2.279508e-02   \n",
       "\n",
       "      svd_v_d_1     svd_v_d_2     svd_v_d_3     svd_v_d_4     svd_v_d_5  \\\n",
       "0  1.355366e-12 -4.675315e-13  1.128586e-06 -6.616693e-14  9.771076e-13   \n",
       "1  4.864432e-16 -4.559207e-15  3.869427e-13  2.265956e-11  1.932551e-14   \n",
       "2  3.142402e-15 -3.986460e-12  5.691485e-12 -1.722264e-12  9.646153e-14   \n",
       "3  2.008314e-13 -1.006827e-13  1.071665e-13 -6.309365e-15  3.790089e-15   \n",
       "4 -1.319163e-13  6.676304e-13 -3.305846e-10  1.529819e-08 -3.385254e-12   \n",
       "\n",
       "      svd_v_d_6      np_dot_u      np_dot_v  \n",
       "0  4.160013e-14  1.114912e-11  2.238770e-12  \n",
       "1  3.825880e-05 -6.409548e-24  1.585891e-09  \n",
       "2  6.396681e-15  2.001676e-21  9.833261e-23  \n",
       "3  3.383652e-16  1.127063e-25  6.977532e-25  \n",
       "4  9.355920e-02  2.911225e-03  2.132690e-03  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a696787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_final_train.indicator_link\n",
    "y_test = df_final_test.indicator_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4705e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train1=df_final_train.drop(['source_node','destination_node','indicator_link'],axis=1)\n",
    "df_final_test1=df_final_test.drop(['source_node','destination_node','indicator_link'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "452594e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:11:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:13:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:13:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:15:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:15:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:15:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:15:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:15:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:15:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:16:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:17:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:17:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:18:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:18:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:18:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:18:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:18:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:19:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:21:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:21:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:21:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:22:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:22:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:22:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:23:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:24:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:25:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:25:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:26:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:26:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:27:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:27:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=-1,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'max_depth': [1, 3, 5],\n",
       "                         'n_estimators': [10, 25, 50, 100]},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "param_dist = {\"n_estimators\":[10,25,50,100],\n",
    "              \"max_depth\": [1,3,5]\n",
    "            }\n",
    "\n",
    "clf=XGBClassifier( n_jobs=-1)\n",
    "\n",
    "rf_random=GridSearchCV(clf, param_grid=param_dist,cv=10,scoring='f1',return_train_score=True)\n",
    "\n",
    "rf_random.fit(df_final_train1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a44c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test scores [0.87992313 0.92695374 0.94345528 0.96385531 0.95058634 0.9717253\n",
      " 0.97506012 0.97802994 0.9664317  0.97461786 0.9779043  0.9814368 ]\n",
      "mean train scores [0.88046912 0.92684262 0.94364017 0.96397667 0.95049174 0.97196739\n",
      " 0.97567607 0.97995541 0.96662082 0.97556401 0.98123731 0.98999857]\n"
     ]
    }
   ],
   "source": [
    "print('mean test scores',rf_random.cv_results_['mean_test_score'])\n",
    "print('mean train scores',rf_random.cv_results_['mean_train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25c343d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=-1,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8761e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "clf=rf_random.best_estimator_\n",
    "clf.fit(df_final_train1,y_train)\n",
    "y_train_pred = clf.predict(df_final_train1)\n",
    "y_test_pred = clf.predict(df_final_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddc3b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1 score 0.989040847749298\n",
      "Test f1 score 0.9236681517768535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('Train f1 score',f1_score(y_train,y_train_pred))\n",
    "print('Test f1 score',f1_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6011877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)  #Recall\n",
    "    \n",
    "    B =(C/C.sum(axis=0))  #precision\n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [0,1]\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap='YlGnBu', fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap='YlGnBu', fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap='YlGnBu', fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02fce8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion_matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Train confusion_matrix')\n",
    "plot_confusion_matrix(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54396a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test confusion_matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHoAAAEWCAYAAAAZwfDzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABWZElEQVR4nO3dd3hUZfrG8e+ThF6lI9WCImBXFAtiQUBRXHtX1B92Vnddu2vXtbuuFbG7iq4NELCBgg17QUARkV5Cb9ISnt8f5yQmIQwTmMnMmbk/1zUXk1PfE+O5Z57znveYuyMiIiIiIiIiItGXk+oGiIiIiIiIiIhIYqjQIyIiIiIiIiKSIVToERERERERERHJECr0iIiIiIiIiIhkCBV6REREREREREQyhAo9IiIiIiIiIiIZQoUe2SxmVsPMhprZUjP73xZs5zQzey+RbUsVMzvQzH5JdTtERNJVvOd8M3vczG6ojDYlm5lda2YDU90OEZFMZWYfmdl54fuzzeyTVLepiJm1NrMVZpab6rZIdlGhJ8OZ2alm9nV4gpljZiPM7IAEbPp4oCnQ0N1P2NyNuPt/3f3wBLQnqczMzWz7WMu4+8fuvmNltUlEJJHMbKqZrQrzYp6ZPWNmtRO5j3jP+e5+gbvfmsh9J5qZdTOzmZtazt3vcPfzKqNNIiKpViZL5prZs4nOknQRHuthsZZx9+nuXtvdCyurXSKgQk9GM7O/AQ8CdxAUZVoDjwJ9ErD5NsAkdy9IwLYiz8zyUt0GEZEEOMrdawN7AHsD15ddQOe7+Ol3JSJZqihLdgN2B65JbXNSQxkgqaRCT4Yys3rALcDF7v6Gu69093XuPtTd/xEuU83MHjSz2eHrQTOrFs7rZmYzzezvZpYf9gbqG867GfgncFJYrT/XzG4ysxdL7L9t2AsmL/z5bDObYmbLzex3MzutxPRPSqy3n5l9Fd4S9pWZ7Vdi3kdmdquZfRpu5z0za7SR4y9q/5Ul2n+MmR1hZpPMbJGZXVti+c5m9rmZLQmXfdjMqobzxoSL/RAe70kltn+Vmc0Fnil5ddfMtgv3sUf489ZmtsDMum3Jf1cRkcrg7rOAEUAnKO7VeLGZ/Qr8Gk7rbWbfh+fNz8xsl6L1zayVmb1hZvPNbKGZPRxOLz7nW+CB8By91Mx+NLOi/T1rZreV2N7/mdnk8Lw6xMy2LjHPzewCM/vVzBab2SNmZuUdV5hV/zOzF8McGWdmO5jZNWE7ZpjZ4SWW72tmE8Nlp5jZ+eH0WuHvZ+swF1aE5/mbzOy1cPvLgLNL5mOYH1PMrG74cy8Lrng33vL/aiIi6cXd5wLvEhR8ADCzfcPMWGJmP5T8bGxmDSzoTTo7PJ+/FU7fyszeDjNlcfi+ZUXbY39+P+kbnu8Xh/mxd5hBS4ryKlx+OzMbFebYAjP7r5nVD+e9QHARfWiYAVeW2P65ZjYdGFViWl54fDPN7KhwG7XDbDuz4r9dkdhU6MlcXYDqwJsxlrkO2Jfg5Lsr0JnSV2+bAfWAFsC5wCNmtpW730jQS+iVsCviU7EaEn4gfgjo5e51gP2A78tZrgEwLFy2IXA/MMzMGpZY7FSgL9AEqApcEWPXzQh+By0IClNPAqcDewIHAv80s23DZQuBy4FGBL+7Q4GLANy9a7jMruHxvlJi+w0Iejf1K7ljd/8NuAr4r5nVBJ4BnnX3j2K0V0QkLZhZK+AI4LsSk48B9gE6WFDEfho4n+B8/QQwxIILCLnA28A0oC3BOXhQObs5HOgK7ADUB04CFpbTlkOAO4ETgebhdsturzdBD6Rdw+V6xDi8o4AXgK3C43uX4PNQC4ILJE+UWDY/3HZdgux5wMz2cPeVQC9gdpgLtd19drhOH+C18Jj+W3LHYX58DjwUZttTwHnuPj9Ge0VEIiksxvQCJoc/tyD4rH8bwWfoK4DXSxS7XwBqAh0JPus/EE7PIfgs3YaguLIKKC7IbIZ9gHYEufMgwXeiw8L9nmhmBxUdAkH+bA3sBLQCbgJw9zOA6YS9l9z97hLbPyhcvlQWufsi4BzgSTMrOr7v3f35LTgWkXKp0JO5GgILNnFr1WnALe6eH37IvBk4o8T8deH8de4+HFgBbO4YNOuBTmZWw93nuPv4cpY5EvjV3V9w9wJ3fxn4meBDeZFn3H2Su68CXqXEFYJyrANud/d1BF8KGgH/dvfl4f7HA7sAuPs37j423O9Ugg/6B21kuyWP6UZ3XxO2pxR3f5LgyvcXBF9OrtvE9kREUu0tM1sCfAKMJijqF7nT3ReF57v/A55w9y/cvdDdnwPWEFw86EzwofgfYW/S1e5e3sCY64A6QHvA3H2iu88pZ7nTgKfd/Vt3X0NwC0AXM2tbYpl/ufsSd58OfEjsbPjY3d8N8/F/QONw/aKsaFt0xdbdh7n7bx4YDbxHcKEgls/d/S13X19eNgAXA4cAHwFD3f3tTWxPRCRq3jKz5cAMgoL5jeH004Hh7j48PEe+D3wNHGFmzQmKQhe4++Lw+8doAHdf6O6vu/sf7r4cuJ1Nf06P5dYwm94DVgIvh9+HZgEfE9xuhrtPdvf3w8/68wkuQsez35vC/Cvv+8F7BNkzkuC7z/lbcBwiG6VCT+ZaCDSy2PeGbk1wZbTItHBa8TbKFIr+ACo8mFp45fMk4AJgjpkNM7P2cbSnqE0tSvw8twLtWVhi4LOiE+28EvNXFa0fdt1/O+xCv4zgy025t4WVMN/dV29imScJbn34T/gFRUQknR3j7vXdvY27X1TmQ+qMEu/bAH8Pu7kvCYtDrQjO462AaZsaw83dRxFckX0EmGdmA4puaSqjVDa4+wqCjNvcbCibAwvKyYqibOhlZmMtuGVsCUEvp01lw4xYM919CcGH/E7AfZvYlohIFB0T9uLvRlDMLzpvtgFOKJMdBxBcEG0FLHL3xWU3ZmY1zewJM5sWfk4fA9S3zX+SVdkc2Nj3gyZmNsjMZoX7fZFNZwBsIgeAAQQZ8Iy7b9CTVSQRVOjJXJ8Dqwm62m/MbIITbpHW4bTNsZKgq2WRZiVnhldPuxOcyH8mKIBsqj1FbZq1mW2qiMcI2tXO3esC1xJ014zFY8204AkDDxJ0zb8pvDVNRCSqSp7zZhD0mKxf4lUz7Ik5A2i9iQsNwQbdH3L3PQm6y+8A/KOcxUplQ3g7cEOSnA0WjFn3OnAv0NTd6wPD+TMbNpYBm8qG3Qi67r9McKuyiEhGCnvkPEtwHoUgH14okx213P1f4bwGRT0qy/g7wV0F+4Sf04uGVdjUZ/UtdSfBOX2XcL+nl9lnhXMgLE49ATwPXGibeKqvyOZSoSdDuftSgnFpHrFgEOKaZlYlvDpZdA/py8D1ZtbYgkGN/0lQqd4c3wNdzay1BQNBF4+ub2ZNzezo8MP5GoJbwMp7xOBwYAcLHgmfZ2YnAR0IxnpItjrAMmBF2NvowjLz5wHbbrBWbP8GvvHgsbrDgMe3uJUiIunhSeACM9vHArXM7EgzqwN8CcwB/hVOr25m+5fdQDj45T5mVoXgYsFqys+Gl4C+ZrZbWHy5A/givM02maoC1YD5QIGZ9SIYV6jIPKBhmHlxMbPqBDl7LcGYPy3M7KLENVlEJO08CHQPi9wvAkeZWQ8zyw3zoZuZtQxv3R0BPGrB4MtVzKyooFOHoKfNkvDC6Y3l7CcZ6hB8b1kSji9U9mLE5nw/KHoYzDkEBbDnt6BnkshGqdCTwdz9fuBvBAMszyeolF8CvBUuchvBfbE/AuOAb8Npm7Ov94FXwm19Q+niTA5BJX42sIjg3tYNPtiGXRd7h8suBK4Eerv7gs1pUwVdQTDQ83KCLzCvlJl/E/Bc2M30xE1tzMz6AD0JbleD4L/DHhY+bUxEJMrc/WuCcXoeBhYTDLR5djivkGBste0JBqqcSXD7bll1Cc63iwluzVrIn1d9S+5rJHADQe+aOcB2wMmJPJ7yhONA9CcYD24xQUYMKTH/Z4ILJlPCbNi63A2Vdicw090fC2/nPR24zczaJfwARETSQDi2zfPADe4+g2DA+mv587vJP/jzO+kZBOO3/Uwwts9l4fQHgRrAAmAs8E7ltJ6bgT2ApQQXbd8oM/9OgovmS8ws1gNiADCzPQm+E5wZZuVdBL1/rk5oq0UIBj9MdRtERERERERERCQB1KNHRERERERERCRDqNAjIiIiIiIiIpIhVOgREREREREREckQKvSIiIiIiIiIiGSIvFQ3YGNqtD5Fo0QLAKum35zqJkha2cG2ZO2KnFtWTX95i/YlybXtHvcrJwSAKd/2TnUTJK0oJySg7xNSRN8npLTMz4m0LfSIiCSDmToyiojIxiknREQklijkhAo9IpJVTHesiohIDMoJERGJJQo5oUKPiGSVKFTgRUQkdZQTIiISSxRyQoUeEckqUTgxi4hI6ignREQklijkhAo9IpJVzHJT3QQREUljygkREYklCjmhQo+IZJUoVOBFRCR1lBMiIhJLFHJChR4RySpRODGLiEjqKCdERCSWKOSECj0iklWiMEq+iIikjnJCRERiiUJOqNAjIlklChV4ERFJHeWEiIjEEoWcUKFHRLJKFE7MIiKSOsoJERGJJQo5oUKPiGSVnAiMki8iIqmjnBARkViikBMq9IhIVolCBV5ERFJHOSEiIrFEISdU6BGRrBKFE7OIiKSOckJERGKJQk6o0CMiWSUKJ2YREUkd5YSIiMQShZxQoUdEskz6n5hFRCSVlBMiIhJL+ueECj0iklVycnTaExGRjVNOiIhILFHIifRvoYhIAlkEKvAiIpI6ygkREYklCjmhQo+IZJUo3FMrIiKpo5wQEZFYopATKvSISFYxs1Q3QURE0phyQkREYolCTqjQIyJZJQoVeBERSR3lhIiIxBKFnFChR0SyShTuqRURkdRRToiISCxRyAkVekQkq0RhlHwREUkd5YSIiMQShZxI/xaKiCRQFCrwIiKSOsoJERGJJQo5oUKPiGSXCNxTKyIiKaScEBGRWCKQEyr0iEhWicLgaSIikjrKCRERiSUKOaFCj4hklSg8DlFERFJHOSEiIrFEISdU6BGRrBKFe2pFRCR1lBMiIhJLFHJChR4RySqWk5vqJoiISBpTToiISCxRyAkVekQku6R/AV5ERFJJOSEiIrFEICdU6BGR7BKBe2pFRCSFlBMiIhJLBHJChR4RyS4RODGLiEgKKSdERCSWCOSECj0ikl0i0NVSRERSSDkhIiKxRCAnVOgRkaziOelfgRcRkdRRToiISCxRyAkVekQku0TgxCwiIimknBARkVgikBMq9IhIdonAPbUiIpJCygkREYklAjmhQo+IZJf0Py+LiEgqKSdERCSWCOSECj0ikl0i0NVSRERSSDkhIiKxRCAnIjBetIhIApnF/9rkpqyVmX1oZhPNbLyZ/TWc3sDM3jezX8N/tyqxzjVmNtnMfjGzHiWm72lm48J5D5kFDTCzamb2Sjj9CzNrm/hfioiIFEtgToiISAaKQE6o0CMi2SXX4n9tWgHwd3ffCdgXuNjMOgBXAyPdvR0wMvyZcN7JQEegJ/ComeWG23oM6Ae0C189w+nnAovdfXvgAeCuLf8liIjIRiU2JzCznmFxf7KZXV3O/HpmNtTMfggvGvRN+DGJiEjiJDAnkpURKvSISHaxCrw2wd3nuPu34fvlwESgBdAHeC5c7DngmPB9H2CQu69x99+ByUBnM2sO1HX3z93dgefLrFO0rdeAQ4t6+4iISBIkMCfCYv4jQC+gA3BKWPQv6WJggrvvCnQD7jOzqgk4EhERSYYE5UQyM0KFHhHJKm4W98vM+pnZ1yVe/Ta23fCWqt2BL4Cm7j4HgmIQ0CRcrAUwo8RqM8NpLcL3ZaeXWsfdC4ClQMMt/DWIiMhGVCQn4tAZmOzuU9x9LTCIoIBfapdAnbCIXxtYRNBjVERE0lACcyJpGaHBmEUku1Rg8DR3HwAM2NRyZlYbeB24zN2XxehwU94MjzE91joiIpIMFciJ8AJAyYsAA8LsKFJegX+fMpt5GBgCzAbqACe5+/qKNFlERCpR4nIiaRmhQo+IZJcE3/RkZlUIijz/dfc3wsnzzKy5u88Jb8vKD6fPBFqVWL0lwUl7Zvi+7PSS68w0szygHkElX0REkqECORHHBYF4ivU9gO+BQ4DtgPfN7GN3XxZ/S0REpNIkLieSlhG6dUtEsktin7plwFPARHe/v8SsIcBZ4fuzgMElpp8cPklrG4JBl78Mb+9abmb7hts8s8w6Rds6HhgVjuMjIiLJkNinqWyswF9SX+AND0wGfgfaJ+RYREQk8RKXE0nLCPXoEZHsEudTUuK0P3AGMM7Mvg+nXQv8C3jVzM4FpgMnALj7eDN7FZhAcG/txe5eGK53IfAsUAMYEb4gKCS9YGaTCXrynJzIAxARkTISmxNfAe3C4v4sgnP4qWWWmQ4cCnxsZk2BHYEpiWyEiIgkUOJyImkZoUKPiGSXBD6wyt0/YeOdNw/dyDq3A7eXM/1roFM501cTFopERKQSJDYnCszsEuBdIBd4Oiz6XxDOfxy4FXjWzMYRZMpV7r4gYY0QEZHESlBOJDMjVOgRkeyiJ5OLiEgsCc4Jdx8ODC8z7fES72cDhyd0pyIikjyJvSCQlIxQoUdEsotGJhMRkViUEyIiEksEckKFHhHJLurRIyIisSgnREQklgjkhAo9IpJVPLGDbIqISIZRToiISCxRyIkIdDpKPy2bN+CdQdfz3ch7+eaDe7j4nJ6l5l/W70hWTX+ZhlvVAaB1y0YsmvQcY0fcydgRd/LQHecWL3vTP07k17EPM3/iM6W2cfrxXZn+3RPF65x98sHltmX3nbfhq/fu4qcxD3DfzWcVT69aNY8XHunPT2MeYMzgW2ndslHxvNOO78q40fczbvT9nHZ81y3+fUj55syZzxlnXEuvXhdy5JEX8dxzQwCYOHEKJ554BX369OfYYy/nxx8nlVpv9ux8dt/9BJ566o1yt7tkyXL69r2Bww/vR9++N7B06YrieU888T+6d+9Hjx4X8PHH3xZP/+mnyRx11CV0796P2257gqx+OndiH5srklBd92vLB2+czajB53DB2XtvML9O7ao8+WAfhg06g3f+dybHH92xeN45p+3BO/87kxGvnsm/7ziCqlVzAahXtzrPP3oco97qy/OPHkfdOtUq7Xhk840Z8w09elxA9+79GDDgfxvMd3duu+0Junfvx1FHXcr48ZOL511zzb/p0uV0eve+uNQ6Dz74IkcddSl9+vTnnHNuYN68hUk/jkhSTkga637Qrvzw4X38NOYBrrjo6A3m169Xi1cG/I0v372Lj4fcSocdWhbPu/TcXnzzwT18/f7dPPefS6lWrQoAO+/Umo/evJmv3ruL156+gjq1a1Ta8cjmS0ZOjBjxCUceeRHt2x/NuHG/Jv0YIisCOaFCz2YoKFzP1be9yO6HXsFBfW7g/DMPp327FkBQBDrkwJ2ZPnN+qXWmTJvHvr2uYd9e19D/2qeKpw//4FsOPPr6cvfz+tDPi9d5dtCH5S7z0O3ncMnVA+nU9XK2a9uMw7vtCsDZJx3M4qUr6dT1cv4zcDi3XxM8pW2rerW47rJj6Xr0DRx49A1cd9mx1K9Xa4t/J7Kh3Nxcrr76HEaMeIxXXrmXl14axuTJ07nnnme4+OKTGTz4If7619O4557SRb477xzIgQfuudHtDhjwGl267MJ77w2gS5ddGDDgNQAmT57OsGFjGDbsEQYOvImbb36MwsLgyd033fQot9xyCe+99wRTp85mzJhvknfg6c4q8BKpRDk5xs1XHULfS9+kx3HPclTP9my/TYNSy5xx4m5MnrKII09+gVP/739ce/lBVMnLoWnj2px18u70Of0lep34PDk5xlE9dgTggr5789mX0znkmGf47MvpXNi3cyoOTyqgsLCQW255nIEDb2LYsEd4++0xTJ48vdQyY8Z8w9Sps3nvvSe49daLuemmx4rnHXvsoQwceNMG2z3vvGMZOvQ/DB78EN267c0jjwxK9qFEk3JC0lROjvHgbX3pc9Zd7H7oFZxw9H7F30GKXHlxH36YMI3OPa7i3Msf497wQvDWTbfior492f/Ia9mr+5Xk5uZwwlFdAHjs7n5c/69B7H34VQx552suP793pR+bVEyycmKHHdrwn/9cy957d9xgnpQQgZxQoWczzM1fwvc/TQVgxcrV/Dx5Fls3Cz6M333jmVx3x0vE22Hiy+8mMzd/yWa1o1mT+tSpXYMvvg2qrS+9/jFH9dgLgN6H78l/XxsDwBvDv6Db/sFTm7sftCsjPx7H4qUrWbJ0JSM/HsfhB+26WfuX2Jo0aUDHjtsDULt2TbbdthXz5i3EzFi5chUAy5evpEmTP7/IffDB57Rs2Yx27VpvdLsjR37BMccET+4+5phD+eCDscXTjzyyK1WrVqFVq2a0adOcH3/8lfz8RaxY8Qe7794eM+OYYw5h5MixyTrs9Jdj8b9EKtGunZoxbeYSZsxayrqC9bz97s9077ZdqWXcnVo1gyuwNWtWYcmy1RQUrgcgNzeH6tXyyM01atSowrz5KwHoftB2vP72BABef3vCBtuU9PPjj7/Spk1zWrVqRtWqVTjyyK6MHPlFqWVGjhzLMcccgpmx227tWbZsJfn5iwDYe+9O1KtXZ4Pt1q5ds/j9qlVrMPVIKZ9yQtLU3rttz29T5zJ1ej7r1hXyv6Gf0/vwvUot075dSz769CcAJv02mzYtG9OkUT0A8vJyqVG9Krm5OdSoUZU58xYD0G7b5nzyxUQARn38I8ccoQsC6S5ZObHddq3YdtuWG0yXMiKQE0kbo8fM2gN9gBaAA7OBIe4+MVn7TIXWLRuxW8e2fPXdZI7sviez5y5i3MTpGyzXtlVjPh9+J8tXrOLme1/h0y9/2eS2+xzRmf332YnJv8/hypufZ+acRaXmb92sAbPm/jlt1tyFxQWnrZs1YObsoEt2YeF6li3/g4Zb1WHrZlsxc3aJdeYsYutmW23WsUv8Zs6cx8SJv7Hrrjty7bX/x7nn/pO77nqa9evXM2jQPQD88cdqnnzydZ5++laefvrNjW5r4cIlxcWhJk0asGjREgDmzVvIrrvuWLxc06aNmDdvIXl5uTRr9uete82aNcru7vr6YpM2siUn4tWscW3mzF1e/POc/BXs1ql5qWWef+V7BjxwDGPf7UetWlXpf/Uw3GHe/BUMfOFrPhl+HqvXFPDJ59P4ZOw0ABo1rMn8BUHRZ/6ClTRsUBNJb/PmLSx13m7atOEGt/mWXaZZs4bMm7ew1MWD8jzwwPO89daH1KlTk+efvyOxDc8Uyom0oZwoLfgc/+dnuFlzFtJ5t+1LLTNu4jT69Nybz776hb123Y7WLRrRonkDvhv3Ow8OeJtJYx9m1eq1jBzzIyM/HgfAhF9m0rv7nrz9/jcce+S+tGzesFKPSyoumTkhcYhATiSlR4+ZXQUMIuis9CXwVfj+ZTO7OsZ6/czsazP7umDF5I0tljZq1azGy09czj9ufp6CgkKuuuQYbrlvw/sj5+YvYYd9L6XLEddw1a0v8OxDl27y3tfhH3xL+/3607nHVYz65CeevP+iDZYp78+raOyV8q7SuftGpsdsimyhlStX0b//nVx77f9Ru3ZNXn55ONdccx6jRz/DNdecx3XXPQTAf/7zX846qw+1am3efdHljbtjtrHp6X9ySpoIdLXMBonIiWULPq+cxlaWcv7myv7/27VLWyZOymffHgPofcqL3HTVIdSuVZW6dapxWLftOKj3U3TpMYAaNarQ54idKqnhkmjxnLfLy+54zu2XX34mo0c/w1FHdePFF9/e7DZmNOVEWsiW7xMVEc/n+HsfHUL9erUYO+JOLuzbgx/GT6WgoJD69WrRu/te7LR/f7bd+yJq1azGyX85AIDz//EE5591OJ8Ou53atWuwdl1BZRyObIFk5oTEIQI5kawePecCHd19XcmJZnY/MB74V3krufsAYABAjdanpHX5IS8vl5efuJxX3vyUwe98RccdW9GmVWO+fOcuAFo0b8Dnw+/gwKOvZ978pSxaGwyY+92435kybR7ttm3Otz9O2ej2Fy35c4Ddp18ayW1Xn7LBMrPmLqJFsz8rsi2aNSzugjlrzkJabt2QWXMXkZubQ906NVm0ZAWz5iziwC5/fvhv0bwBH3+elRdFKsW6dQX0738nRx3VjcMP3w+AN98cxXXX9QOgV68DuP76/wDwww+TePfdz7j33mdZtmwlOTlGtWpVOf300vdJN2xYn/z8RTRp0oD8/EU0aFAfCHrqzJ27oHi5efMW0KRJww2mz527ILsr+Xm6YzVNbHFObLvH/WmdExU1N38FzZv92Y26eZPa5M9fUWqZ44/uyOPPfgXAtBlLmDF7Kdu2bUCL5nWYOWsZi5YEt4W+O+pX9tylOYOHT2TBwj9o3KgW8xespHGjWixc9EflHZRslg3P5xtegW3WrGGZc3vFrtL27n0Q559/M/37n7blDc40yol0kfHfJypq1pxFtNz6z942LZo3ZHb+4lLLLF+xivOveKL4558/fYipM+bT/aBdmDojnwWLgp6jb73zFfvuuQOD3vyESb/N5qjT7wRg+22a0euQ3ZJ/MLJFKiMnJIYI5ESyWrge2Lqc6c3DeZH3+D39+GXybB4aOByA8b/MoM0eF9B+//60378/s+YsossR1zJv/lIaNahDTnh/XtvWTdh+m2b8Pm1ezO03a1K/+H3v7nvyy+RZGywzN38JK1aupvPuQZfNU487kLffCwbZHfb+N8VP1Dr2iH0Y/dl4AN4f/QOHHbgL9evVon69Whx24C68P/qHLftlSLncneuue4htt21F377HFE9v0qQBX34Z3Ds9duyPtG0b/K/y0kt3MWrUU4wa9RRnnXU0559/wgZFHoBDDunMW2+NBOCtt0Zy6KH7FE8fNmwMa9euY8aMuUydOptddmlHkyYNqFWrBt9//zPuzltvjeLQQ/dN8tGnL7f4X5JUGZ8TFfXj+Lm0bVWfllvXpUpeDr17tOeD0aUvCMyeu5z9OgdjeDVqUJNt2zRgxqwlzJ67nN12bkb16sH1m/06t2by78Ftuh+MmcJxvTsAcFzvDrw/+rdKPCrZHDvv3I6pU2czY8Zc1q5dx7BhYzjkkNJjZhxyyD689dYo3J3vv/+ZOnVqbvID/NSps4vfjxr1hcZh2AjlRNpQTpTx9Q+/sf02zWjTqjFVquRywlFdGPZ+6Qds1KtbkypVgqcu9j3lED75ciLLV6xixqwFdN6jHTWqVwXg4P07FX+/aNywLhD09ri6/1948sWRlXhUsjmSlRMSnyjkRLJ69FwGjDSzX4EZ4bTWwPbAJUnaZ6XZb+8dOe24roybOJ2xI4Lq9413v8K7H35f7vIH7LMTN/z9BAoKCiksXM+l1z7F4qXBeAm3X3sqJ/XZj5o1qjL5i4d5ZtCH3P7A61zUtydHdt+TgoJCFi9Zwf/9/fHi7Y0dcSf79roGgP7XPc2A+y6gRvWqvPfh98VtePaVj3j6wYv4acwDLF6ygjMuCXqNLF66kjsfepNPht4GwB3/fqO4LZJY33wzgcGDP2SHHdrSp09/AP72tzO59dZLuOOOJykoKKRatarccsum/5e47rqHOPnkXuy8czv69Tueyy67i9dee5/mzRvz738HvZfbtWtDr14HcMQRF5Gbm8s//3kBublB0N9000Vcc82DrF69lq5d96Rr140/1SvjafDMdHEZGZwTm6Ow0Lnprg957pHjyMkx/jfkJ36dspBTj9sFgJde/5H/PDmWe27uwYhXzgSDux76mMVLVrN4yVzeGfkrQ/97OgWF65nwSz6D3gjGXnj8mS95+K7enHhMJ2bPXc7FV+p2nXSXlxecw88770YKC9dz3HGH0a5dG15+eQQAp5zSi4MO2ovRo7+me/d+1KhRjTvu+Gvx+n/72z18+eU4Fi9eRteuZ3PppadywgmHc999z/L777Mwy6FFi8bcfPPFG2tCdlNOpIvLUE6UUli4nstveJahL1xDbm4Oz73yERMnzeS80w8DYOCLH9B++xYMfOBCCgvX8/Ovs7jgygEAfPX9b7w5/As+H34HBYXr+WH8VJ56KSjonNhnP84/83AABr/zJc+/+lFKjk/il6yceP/9z7n11idYtGgp559/CzvttA1PPXVLqg4zfUUgJ6y8+/sSsmGzHKAzweBpBswEvnL3wnjWz7SulrL5Vk2/OdVNkLSywxadWbc9//W4zy1Tnjgu/c/iEbalOZFpt27J5pvyrR4FLCUpJzKFvk9Iouj7hJSW+TmRtKduuft6IIuf4SwiaSkCFfhsoZwQkbSknEgbygkRSUsRyImkFXpERNJS+o+dJiIiqaScEBGRWCKQEyr0iEh2yY3AmVlERFJHOSEiIrFEICdU6BGRrOKW/l0tRUQkdZQTIiISSxRyQoUeEcku6V+AFxGRVFJOiIhILBHICRV6RCS7RGDwNBERSSHlhIiIxBKBnFChR0SySwS6WoqISAopJ0REJJYI5IQKPSKSXXLT/8QsIiIppJwQEZFYIpATKvSISFbxCHS1FBGR1FFOiIhILFHICRV6RCS7RODELCIiKaScEBGRWCKQEyr0iEh2icA9tSIikkLKCRERiSUCOaFCj4hklwg8DlFERFJIOSEiIrFEICdU6BGR7BKBCryIiKSQckJERGKJQE6o0CMi2SUvAiV4ERFJHeWEiIjEEoGcUKFHRLKKR6ACLyIiqaOcEBGRWKKQEyr0iEh2Sf8CvIiIpJJyQkREYolATmyyiWZWy8xywvc7mNnRZlYl+U0TEUkCs/hfEhflhIhkFOVEwiknRCSjRCAn4qlFjQGqm1kLYCTQF3g2mY0SEUmaHIv/JfFSTohI5lBOJINyQkQyRwRyIp5Cj7n7H8CxwH/c/S9Ah+Q2S0QkSSJwYo4g5YSIZA7lRDIoJ0Qkc0QgJ+IZo8fMrAtwGnBuBdYTEUk7nqsP5kmgnBCRjKGcSArlhIhkjCjkRDwn2MuAa4A33X28mW0LfJjUVomIJIvGVEiGy1BOiEimUE4kw2UoJ0QkU0QgJzZZ6HH30cBogHAQtQXu3j/ZDRMRSQp1tU845YSIZBTlRMIpJ0Qko0QgJ+J56tZLZlbXzGoBE4BfzOwfyW+aiEgSWAVeEhflhIhkFOVEwiknRCSjRCAn4hmMuYO7LwOOAYYDrYEzktkoEZFkycmJ/7UpZva0meWb2U8lpt1kZrPM7PvwdUSJedeY2WQz+8XMepSYvqeZjQvnPWQW9Ac1s2pm9ko4/Qsza5vQX0biKCdEJGMkMiekmHJCRDJGFHIinl1XMbMqBCfmwe6+DvCktkpEJEkSfGJ+FuhZzvQH3H238DUcwMw6ACcDHcN1HjWz3HD5x4B+QLvwVbTNc4HF7r498ABw12YddPIpJ0QkYyT6A7yZ9QwL/JPN7OqNLNMtvDgw3sxGJ/J40oRyQkQyRoIvHCclI+KJqCeAqUAtYIyZtQGWxbNxEZF0Y2ZxvzbF3ccAi+LcdR9gkLuvcfffgclAZzNrDtR198/d3YHnCT4IF63zXPj+NeBQi6dhlU85ISIZI5E5ERb0HwF6ETxO/JSw8F9ymfrAo8DR7t4ROCHhB5V6ygkRyRiJyolkZsQmCz3u/pC7t3D3IzwwDTg4no2LiKQbs4q8rJ+ZfV3i1S/O3VxiZj+Gt3ZtFU5rAcwosczMcFqL8H3Z6aXWcfcCYCnQcDMPPWmUEyKSSSqSE3HoDEx29ynuvhYYRFDEL+lU4A13nw7g7vmJPJ50oJwQkUySwJxIWkbE83h1zOxIgtsNqpeYfEs864qIpJOK9Idx9wHAgAru4jHgVoIu6bcC9wHnUP5wbB5jOpuYl1aUEyKSKSqSE+EFgJIXAQaE2VGkvCL/PmU2swPBrU0fAXWAf7v78xVociQoJ0QkUyQwJ5KWEZss9JjZ40BNgqr7QOB44MtNrSciko4syYOiufu84n2ZPQm8Hf44E2hVYtGWwOxwestyppdcZ6aZ5QH1iP9WsUqjnBCRTFKRnIjjgkA8Bfs8YE/gUKAG8LmZjXX3SfG3JL0pJ0QkkyQwJ5KWEfE0cT93P5NgQNCbgS6U/rIiIhIZCe6SX872rXmJH/8CFD2RawhwcvgkrW0IBl3+0t3nAMvNbN9w/J0zgcEl1jkrfH88MCocxyfdKCdEJGMkOCc2VuQvu8w77r7S3RcAY4BdE3EsaUQ5ISIZI4E5kbSMiOfWrVXhv3+Y2dbAQmCbONYTEUk7uQns0WNmLwPdgEZmNhO4EehmZrsRVOOnAucDuPt4M3sVmAAUABe7e2G4qQsJnuBVAxgRvgCeAl4ws8kEPXlOTlzrE0o5ISIZI5E5AXwFtAsL/LMIzuOnlllmMPBw2HOzKkG3/QcS2orUU06ISMZIYE4kLSPiKfS8HY70fA/wLcGXl4FxN11EJI0k8plV7n5KOZOfirH87cDt5Uz/GuhUzvTVROPpK8oJEckYCc6JAjO7BHgXyAWeDgv/F4TzH3f3iWb2DvAjsB4Y6O4/bXyrkaScEJGMkaicSGZGbLLQ4+63hm9fN7O3geruvnRzD0ZEJJXS8+nk0aacEJFMkuiccPfhwPAy0x4v8/M9BEWQjKScEJFMksicSFZGbLTQY2bHxpiHu79RkR2JiKSDZA/GnE2UEyKSiZQTiaOcEJFMFIWciNWj56gY8xzQiVlEIkcdehJKOSEiGUc5kVDKCRHJOFHIiY0Wety9b2U2RESkMuREoAIfFcoJEclEyonEUU6ISCaKQk7EunXrb8BSd3+qzPRLgVx3fzDJbRMRSbicCFTgo0I5ISKZSDmROMoJEclEUciJWLWoc4AXypk+IJwnIhI5ZvG/ZJOUEyKScZQTCaWcEJGME4WciDVGj7v72nImrjE9tkZEIkpnr4RSTohIxtHZK6GUEyKScaJw9or5eHUza+ru88pOS26TRESSx6LQ1zJClBMikmmUE4mlnBCRTBOFnIh169Y9wDAzO8jM6oSvbsBQ4N7KaJyISKJFoatlhCgnRCTjKCcSSjkhIhknCjkR66lbz5vZfOAWoBPBIxDHAze6+4hKap+ISEJFYZT8qFBOiEgmUk4kjnJCRDJRFHIi5q1b4QlYJ2ERyRgR6GkZKcoJEck0yonEUk6ISKaJQk7ELPSIiGQadbUXEZFYlBMiIhJLFHJChR4RySoWga6WIiKSOsoJERGJJQo5oUKPiGSVKFTgRUQkdZQTIiISSxRyYqOFHjP7W6wV3f3+xDdHRCS5LApn5ohQTohIJlJOJI5yQkQyURRyIlaPnjqV1goRkUoShVHyI0Q5ISIZRzmRUMoJEck4UciJWI9Xv7kyGyIiUhkiUICPDOWEiGQi5UTiKCdEJBNFISc2OUaPmVUHzgU6AtWLprv7OUlsF7N+PSWZm5cI2Xb3IalugqSRKd9dsUXrR+FxiFGTqpz4duxOydy8REiN1jemugmSRlZNf3mL1ldOJF7qvk+cmszNS4S02+vdVDdB0sivX++wRetHISfi6XT0AtAM6AGMBloCy5PZKBGRZMmx+F8SN+WEiGQM5URSKCdEJGNEISfiKfRs7+43ACvd/TngSGDn5DZLRCQ5cszjfknclBMikjGUE0mhnBCRjBGFnIjn8errwn+XmFknYC7QNmktEhFJojxdgU0G5YSIZAzlRFIoJ0QkY0QhJ+Ip9Awws62AG4AhQG3gn0ltlYhIkugKbFIoJ0QkYygnkkI5ISIZIwo5sclCj7sPDN+OBrZNbnNERJJLYyoknnJCRDKJciLxlBMikkmikBPxPHWrGnAcQffK4uXd/ZbkNUtEJDniGZhMKkY5ISKZRDmReMoJEckkUciJeG7dGgwsBb4B1iS3OSIiyRWFCnwEKSdEJGMoJ5JCOSEiGSMKORFPoaelu/dMektERCqBReCe2ghSTohIxlBOJIVyQkQyRhRyIp5Cz2dmtrO7j0t6a0REkiwKo+RHkHJCRDKGciIplBMikjGikBPxFHoOAM42s98Juloa4O6+S1JbJiKSBFEYJT+ClBMikjGUE0mhnBCRjBGFnIin0NMr6a0QEakkUbinNoKUEyKSMZQTSaGcEJGMEYWc2Gihx8zquvsyYHkltkdEJKmiMEp+VCgnRCQTKScSRzkhIpkoCjkRq0fPS0BvgtHxnaCLZREHtk1iu0REkiIKFfgIUU6ISMZRTiSUckJEMk4UcmKjhR537x3+u03lNUdEJLmicE9tVCgnRCQTKScSRzkhIpkoCjmxyTF6zGyPciYvBaa5e0HimyQikjxRGCU/apQTIpJJlBOJp5wQkUwShZyIZzDmR4E9gB8JulvuDPwANDSzC9z9vSS2T0QkoaJQgY8g5YSIZAzlRFIoJ0QkY0QhJ+IZR2gqsLu77+XuewK7AT8BhwF3J69pIiKJl2PxvyRuU1FOiEiGUE4kxVSUEyKSIaKQE/EUetq7+/iiH9x9AsGJekrymiUikhyJPDGb2dNmlm9mP5WY1sDM3jezX8N/tyox7xozm2xmv5hZjxLT9zSzceG8h8zMwunVzOyVcPoXZtY2ob+MxFFOiEjGiMIH+AhSTohIxohCTsRT6PnFzB4zs4PC16PAJDOrBqxLcvtERBIqpwKvODwL9Cwz7WpgpLu3A0aGP2NmHYCTgY7hOo+aWW64zmNAP6Bd+Cra5rnAYnffHngAuKsCh1qZlBMikjESnBOYWc+wwD/ZzK6OsdzeZlZoZsdv0QGkJ+WEiGSMROZEsjIinn2fDUwGLgMuB6aE09YBB8ezExGRdJGX43G/NsXdxwCLykzuAzwXvn8OOKbE9EHuvsbdfyc4r3Y2s+ZAXXf/3N0deL7MOkXbeg04tKi3T5o5G+WEiGSIROZEWNB/BOgFdABOCQv/5S13F/Bugg8nXZyNckJEMkSiciKZGbHJwZjdfRVwX/gqa0W8OxIRSQfxXoHdAk3dfQ6Au88xsybh9BbA2BLLzQynrQvfl51etM6McFsFZrYUaAgsSF7zK045ISKZJME50RmYXHSLkpkNIijiTyiz3KXA68Deid19elBOiEgmSWBOJC0jNlroMbNX3f1EMxsHbFCKcvdd4t2JiEi6qMi9smbWj+CWqiID3H3AZu66vD17jOmx1kkLygkRyUQJzonign1oJrBPmW20AP4CHEKGFXqUEyKSiRKYE0nLiFg9ev4a/ts73o2JiKQ7q8DjEMOTcEULO/PMrHnYm6c5kB9Onwm0KrFcS2B2OL1lOdNLrjPTzPKAemx4q1gqKSdEJOMkOCfiKdg/CFzl7oXpeXfuFlFOiEjGSWBOJC0jNlroCb+k5AJPufthcW9RRCSNVcLo90OAs4B/hf8OLjH9JTO7H9iaYNDlL8OT9nIz2xf4AjgT+E+ZbX0OHA+MCsfxSQvKCRHJRAnOiY0V+UvaCxgUfoBvBBxhZgXu/lZCW5ICygkRyUQJzImkZUTMMXrCLyB/mFk9d19a4WaLiKSZRI69YGYvA92ARmY2E7iRoMDzqpmdC0wHTgBw9/Fm9irBPbcFwMXuXhhu6kKCJ3jVAEaEL4CngBfMbDJBT56TE9j8hFBOiEimSfAYPV8B7cxsG2AWwXn81JILuPs2Re/N7Fng7Uwo8hRRTohIpklgTiQtIzY5GDOwGhhnZu8DK0vssH88LRcRSSfxPCUlXu5+ykZmHbqR5W8Hbi9n+tdAp3KmryYsFKU55YSIZIwE50SBmV1C8KSUXODpsPB/QTj/8YTtLL0pJ0QkYyQqJ5KZEfEUeoaFLxGRyKuEW7eykXJCRDJGonPC3YcDw8tMK/fDu7ufndi9pw3lhIhkjETmRLIyIp5CzyvA9gSDAv0WXmEWEYmk3FQ3IDMpJ0QkYygnkkI5ISIZIwo5Eevx6nnAHcA5wDSCW9FamtkzwHXuvq5ymigikjg5FRglX2JTTohIJlJOJI5yQkQyURRyItY4QvcADYBt3H1Pd98d2A6oD9xbCW0TEUm4HIv/JZuknBCRjKOcSCjlhIhknCjkRKxbt3oDO5R8lK+7LzOzC4Gfgb8mu3EiIommD+YJpZwQkYyjnEgo5YSIZJwo5ESsQo+XPCmXmFhoFoG+SiIi5aiS4OfmZjnlhIhkHOVEQiknRCTjRCEnYjVxgpmdWXaimZ1OUIEXEYmcHPO4X7JJygkRyTjKiYRSTohIxolCTsTq0XMx8IaZnQN8QzBK/t5ADeAvldA2EZGEi0JXywhRTohIxlFOJJRyQkQyThRyYqOFHnefBexjZocAHQEDRrj7yMpqnIhIokXhcYhRoZwQkUyknEgc5YSIZKIo5ESsHj0AuPsoYFQltEVEJOmiUIGPGuWEiGQS5UTiKSdEJJNEISc2WegREckkVXI0poKIiGycckJERGKJQk6o0CMiWSUKFXgREUkd5YSIiMQShZxQoUdEskoUTswiIpI6ygkREYklCjmhQo+IZJUonJhFRCR1lBMiIhJLFHJChR4RySq5lv731IqISOooJ0REJJYo5IQKPSKSVXJS3QAREUlrygkREYklCjmhQo+IZJW8KJyZRUQkZZQTIiISSxRyQoUeEckqUehqKSIiqaOcEBGRWKKQEyr0iEhWicLgaSIikjrKCRERiSUKOaFCj4hklSicmEVEJHWUEyIiEksUckKFHhHJKlE4MYuISOooJ0REJJYo5IQKPSKSVarkpP89tSIikjrKCRERiSUKOaFCj4hklQgMki8iIimknBARkViikBMq9CTAmjXruLDvY6xbW0Bh4XoOPmxn/u/iHjzx8Dt8/OF4cnKMrRrU5vpbT6Jxk3qMHzedu255DQB3OPfC7nQ7dGcAHn9oBCOGfsPyZasY9cXtG93ncwNHMfTNL8nNyeHyq/uw7/47AvDzhJncev0rrFmzjv0ObM/lV/XBzFi7toBbrhvEzxNmUq9eTW6753Sat2iQ/F9OFmjetA733tqLxg1rsd6dQa//yLMvf0uvw3bgrxfsx/bbNOQvZ7zIuAnzAMjLy+HOf/agU/sm5Obm8Oaw8Tz29JfUqlmFV54+pXi7zZrUZvDwidx674ece/qenPiXXSgsWM+ixX9w5c3vMnvOsg3a0mmnptxzc0+qVcvjo09/55a7RwFQtUou997ai047NWXJ0tVcetVQZoXrH3tURy45b18AHh44ljeGjk/2ryylotDVUrLX559M5P673mB9oXP0sfty1nmHlZo/dco8br3hJX6ZOJML+h/J6WcfAsC8uYu56dr/smjBMiwnh2OO78LJpx8EwNKlK7n+iueYPXsRW2/dgNvvPZu69WpW+rFJxXQ/aFfuvelMcnNzeHbQh9z76JBS8+vXq8UT95zPNm2asmbNWs6/4gkmTJoJwKXn9uLsUw7B3Rn/8wz6XfE4a9as44VH+tNu2+bB+nVrsWTZSvbtdU2lH1u6U05IOvv8k5958K7BFK5fz9HH7sOZ5x5Sav7U3/O5/YZX+GXiTM6/tBennd0NKPq+8miJ7yu78H8X9wDgP/cN5ZPRE6hSJY8WrRpy/S0nUadujco+NKmgA7u05vorupKbY7z61gQGPPdNqfm1a1XlvlsPp3mzOuTlGk+9+B2vD50IQJ3aVbnjhkNpt11DcOfqW0by/bi57LRDI2655mCqVc2loHA9N901mh/Hz0vF4aW1KOSECj0JULVqHg8PPJ+aNatRsK6Q8896hC4HtOf0s7tx/iU9AXj1v5/w9BMfcNUNx7Hd9s14+uW/kpeXy4L5yzjz+Ps54KAO5OXlcsBBHTj+lP05sfddG93f77/N44N3vuelN69gQf4y+vd7gleGXkVubg533/YGV994HJ12acPfLnqKsZ/8QpcD2zP0jS+pU7cGrw27mvdHfM8jDw7ntntOr6xfUUYrKFzPHfd/xPif86lVswpDXjqDT76YxqTfFnDh3wdz+/WHl1r+iMN2oGrVXHqd+BzVq+fx3ut9GTLiZ2bNWUbvk58vXm7wf0/nnVG/AjD+53z6nPYCq1cXcNoJu3L1X7vS/+q3N2jLrdcexrW3vcd3P87h6YeP46D9t2H0p79z4jE7s2z5ag7p8xS9e+zIVeH69epWp3+/LvQ57UXcnSEvncEHH01m2fI1yf2lpVBuBE7Mkp0KC9dzz+2v8Z8BF9KkWX3OPvl+Djy4E9tu16x4mbr1avL3a45j9KhxpdbNzc3hr1f0oX2HVqxcuZqzTrqPzl12ZNvtmvH8UyPZa58dOOu8w3hu4Ac8/9QHXPK3oyv78KQCcnKMB2/ry5Gn3cGsOQv5ZOjtvP3+N/z866ziZa68uA8/TJjGSf3uZ4fttubB2/pyxCm3s3XTrbiob092P/QKVq9Zx4uP/pUTjurCi6+N4YyLHype/1/Xn87S5X+k4vDSnnJC0lVh4Xruu+NN/j2gH02a1uOcU/7Ngd06sE3JnKhbg8uv7sOYUaUv3AXfVy4o8X3lYboc0J5Ou7ahc5cduPCvR5CXl8sjD7zN80+N5OLLe1f24UkF5OQYN13VjbMvfou581bw+vMnMWrMFCb/vrh4mdNP3IXJvy/i/L+9TYP61Xn39TMYMuIX1hWs5/orujLms2lcetUIquTlUL16UBa4sv/+/OfJLxnz2TQO2r8NV/bfj9PPfzNVh5m2opATUeh1lPbMjJo1qwFQUFBIQcF6zIxatasXL7Nq1VqK/h6q16hKXl4uAGvXFID9+ZfSadc2NGpcN+b+xnw4nsN67kbVqnls3bIBLVs3YsJP01kwfxkrV6xm513bYmb0OmpPRn/4EwAffzSeI47eE4CDu+/M11/8inv631sYBfMXrGT8z/kArPxjHZN/X0SzxrX57fdF/D5t8QbLO1CzehVyc43q1fJYt66QFSvXllqmbev6NGxQk6++Da7Ojv16BqtXFwDw3Y9zaNa0zgbbbdyoFrVrVeW7H+cA8Obb4+nebXsADuu2Ha+HPXVGfDCJ/Tq3BqDrfm35ZOw0li5bzbLla/hk7DQO2n+bBPxW0leOedwvkco0Ydw0WrZuRItWjahSJY/uvXZnzIelCzoNGtahQ6fW5OWVju9GjevRvkMrAGrVqk7bbZoyf95SAMZ8OI4j++wNwJF99mZ0mW1K+tl7t+35bepcpk7PZ926Qv439HN6H75XqWXat2vJR58GGT/pt9m0admYJo3qAZCXl0uN6lXJzc2hRo2qzJm3YRYd13tfXh38WfIPJoKUE5KuJvw0nZatG9KiZUOqVMnjsJ67MebD0gWdjeVE+d9Xgnn77Ldj8XeTjru0IT/MD0lfu3RsyrQZS5gxaxnrCtYz7L1JHHrQtqWWcXdq1awCQM2aVVm6bDUFheupXasKe+++Nf8bPAGAdQXrWb5ibfE6tWtVBYJeP/nzV1biUUVHFHJCPXoSpLBwPX1PfpCZ0xdy3Mn70XGX4It00a1YtWtX5+GnLihefvyP07n9xleZO3sx/7zj5OKTazzm5y+lU7h9gMZN6zF/3jLy8nJp0rRe8fQmTesxPz+4PWf+vKU0bVofCD4A1q5dnaVL/qD+VrW25LCljBbN69JxxyZ8/9OcjS4z4oNJHNZte8a+fyE1qlfhtns/ZOmy1aWWOarnTgx775dy1z/xmJ0Z/envG0xv1qQ2c/NXFP88d95ymjWpDUDTJnWYM3c5AIWFzvIVa9mqfg2aNq7NnHnL/1wnfzlNG9eO/4AjKApdLSU75ecvpWmzrYp/btK0PuN/nFbh7cyetZBJP8+k4y5tAFi0cDmNGgfZ0KhxPRYvXBFrdUkDWzfbipmzFxb/PGvOQjrvtn2pZcZNnEafnnvz2Ve/sNeu29G6RSNaNG/Ad+N+58EBbzNp7MOsWr2WkWN+ZOTHpYt7+3duz7wFS/lt6txKOZ6oUU5Iupo/bylNws/zEObEuPhz4s/vKwvC7yttNljm7Te/5LCeuyWgtZJMzZrUYs68Ep/781ewa6dmpZZ58dUfefz+3nz6zjnUqlmFy655F3do1aIei5as5q4bD6P9Do34aWI+t907hlWrC7j9vo95+uE+XP3X/bEc46RzXqvsQ4uEKOREpffoMbO+Meb1M7Ovzezr5wa+W5nN2mK5uTk8/7+/Mfj965nw0wx++zX48HRB/14Mfv96Dj9yD157+dPi5Tvu0pqX3ryCp1/uz/NPfciaNevi3ld5PXHMgvF+NphetE4527EI/IFGSc0aVXj03qO59d4PN+ihU9KuHZuxvnA9XQ5/nIOOfJLzztiLVi3qlVqmd4/2DH3n5w3W7XPETuzcoSlPPvfVBvOMDf+DFv1NlPff2t2xcmZk+vXJPIv/JakRb048O3BEZTYr+co7h1fwRP3HH2u4+vJnuPyqv1C7RK9SiZZyz81l/j7ufXQI9evVYuyIO7mwbw9+GD+VgoJC6terRe/ue7HT/v3Zdu+LqFWzGif/5YBS657YZz/+p948G6WcSH/xf594pzKblXTlf56P/w/xz+8rN4TfV0pfmHx2wAfk5uXS48g9trClknzl5UTpv5ADu7Rm4qT57N/zaY4+dRD/vLIrtWtVITc3h447Nual18bR57RBrFq1jvPPDu78OPX4nbnj/o/p2vtZ7rj/Y+644dBKOZqoiUJOpOLWrZs3NsPdB7j7Xu6+11nn9ajMNiVMnbo12GOvbRn7aekv6YcfsTsffbBhd/m22zalRo2qTJkc/1W1Jk3rM2/un10q589bSqMmdWnStF6prpb54fRgnXrMm7cECLprrlixWoNxJlBeXg6P3ns0Q0ZM5N1wXJ2NObrXToz+bCoFBetZuPgPvvl+Fjt3+LMC336HxuTlGj9NLD3w2f77tObic/el32VvsXZd4QbbnZP/Zw8egGZN6zBvflDpnztvOc2bBbd75eYadWpXZcnS1czNX07zEreBNWtSh/z5mX213yz+l6RMXDlx9nm9KrNNSdekaT3mzf3zFpv8eUuKz+HxKFhXyNWXP03PI/fk4MN2LZ7eoGEdFswPsmHB/KVs1TCze+1lgllzFtFy64bFP7do3pDZ+aVvv1q+YhXnX/EE+/a6hnMve5RGDeoydcZ8DjmgE1Nn5LNg0XIKCgp5652v2HfPHYrXy83NoU/Pzrw29PNKO56oUU5EQpzfJ3pWZpuSLvisv6T45/x5SzY55EN5gu8r2zH20z97jw8b/BWfjpnIzXeeWuGLDFL55uavoHnTEp/7m9Te4Dar447qwHujpgAwfeZSZs5exrZtGzA3fwVz81fwQzjI8jsjf6Nj+yYA/KV3e94d9RsAIz6YzK4dm1bG4UROFHIiKYUeM/txI69xQMb9tSxetILly1YBsHr1Or4aO5k22zRhxrT5xct88tF42mwT/A80e+YiCgqCL+pzZi9m+tT5NN86/idgHditAx+88z1r1xYwe+YiZkxbQIdOrWnUuC61alXjpx+m4e6MGPoNXQ/uCMAB3TowfEgwEvuH749jz87b6ySeQP+6sQe//b6Ip178ZpPLzp67nP32Dm69q1G9CrvtsjVTpv7ZRf/onhv25umwYxNuu+5w+l3+JgsXlz945vwFK1n5xzp22zl4ospfenfkg9GTARg5+jeOOyr4W+h12A58/tUMAMZ8NpUDu7Slbp1q1K1TjQO7tGXMZ1MrdvARYxV4SfJkW07EY6dOrZkxbQGzZy5k3boC3h/xHV27dYprXXfnthtfpu22TTn1rINLzTuwWyeGDQ56AQ4b/BVdD9454W2XxPr6h9/YfptmtGnVmCpVcjnhqC4Me790vtSrW5MqVYLbvvuecgiffDmR5StWMWPWAjrv0Y4a1YMxFg7evxO/TP5zEOdDDtiZSb/NZtbcRZV3QBGjnEgPyokN7dSxVamc+OCd7zmwW8e41t3w+8qvxd9NPv/kZ1585kPufqgv1WtUTVr7JXHGTZhH21b1abl1Xark5XDk4TswckzpoR1mz11Ol84tAWjYoAbbtNmKGTOXsmDhH8yZt4Jt2tQHoEvnlkyeEmRC/vyVdN6zRTB975ZMnbGk0o4pSqKQE5aMAXnNbB7QAyg7+p8Bn7n71pvaxqI1QyJzB8nkSbO55fpXWF+4Hl/vHNJjV869oDvXXP4c06fOx3KMZs234sobjqNJ03qMGPoNLzz9IXl5OZjlcM4Fh3HQIcGH+Yfvf5v3hn/PgvnLaNS4Lkcf25nzLjqcjz8cz8QJM+kXPgbx2QEjefutL8nNzeWyK4+my4HtAZg4fga3hY9X3/eA9vz9mmMwM9asWcfN1w5i0s+zqFuvJrfefRotWjbc6DGlk732nZTqJsS0124tePWZU/h50nzWh/8/3fvwx1StksuNVx1Kg61qsHz5Gib8ks/ZF79OzRpVuPvmnmy/bUPMjNcG/8STz/95K9ZHQ8/jnEvfYMrUPz+Ev/D4Cey4fSPyFwSV+tlzl9HvsrcAeHvQmcVP69q5Q1PuvrkX1avlMfrT37nprpEAVK2ay/23HUGHHZuwdNlq+l/9NjNmBVf4T+jTiQvP2QeAR5/6gteG/JTcX9gWmvLdFVt0zvx6wbC4zy17NTpSn+OTJBE5sWTtiMjkRLw+HTOBB+5+k/WF6znqL/vQt9/hvPFqcNvvsSfuz8IFyzjrpPtYuXI1OTlGjRrVGDT4GiZPms35Zz3E9u2aY+GN4xf2783+XTuwdMlKrr3iWebOWUyz5ltxx31nU69eZo3P1nz75ze9UMT0OHg37rkxeLz6c698xN0Pv8V5px8GwMAXP2CfPdox8IELKSxcz8+/zuKCKwewZGmQEdf/7XiO770vBYXr+WH8VC68cgBr1wYD+g+47wK+/G4yA1/8IGXHlmyrpr+snMgAifk+MTTjcuKzjyfy4N2DWV/o9D5mb87udxhvvBrcinnsifuxcMEy+p7871I58fJb/2DO7EXccv0g1hc6vn59+H0leDLs8Ufeybq1BdSrH2RDx11ac9UNx6fsGJNhn/2nproJCXfQ/m247m8Hkpubw2tDJvDY019zynHBd8qXX/+JJo1qcddNh9G4UU3MjCee/YYhI4JeXDvt0Ijbrz+EKlVymTFrGVff/AHLlq9hz12bB49sz81h7doCbvzXR4z/eX6sZkTSr19fmvE5kaxCz1PAM+7+STnzXnL3Uze1jSgVeiS50r3QI5VrSws931bgxLyHPsAnTSJyIhMLPbJ5MrHQI5tvSws9yon0kJjvE5lX6JHNk4mFHtl8W1roiUJOJOWpW+5+box5mzwpi4gki+lxuGlBOSEi6Uo5kR6UEyKSrqKQE3q8uohklSg8DlFERFJHOSEiIrFEISdU6BGRrBKB87KIiKSQckJERGKJQk6o0CMiWSUKFXgREUkd5YSIiMQShZxIyuPVRUTSVaIfh2hmU81snJl9b2Zfh9MamNn7ZvZr+O9WJZa/xswmm9kvZtajxPQ9w+1MNrOHzCwCESIiknmi8NhcERFJnSjkhAo9IpJVzOJ/VcDB7r6bu+8V/nw1MNLd2wEjw58xsw7AyUBHoCfwqJnlhus8BvQD2oWvnlt6rCIiUnGJzgkz6xkW9yeb2dXlzD/NzH4MX5+Z2a6JPiYREUmcROZEsjJChR4RySo5FXhtgT7Ac+H754BjSkwf5O5r3P13YDLQ2cyaA3Xd/XN3d+D5EuuIiEglSmROhMX8R4BeQAfglLDoX9LvwEHuvgtwKzAgAYchIiJJkqicSGZGqNAjIlklx+J/mVk/M/u6xKtfOZt04D0z+6bE/KbuPgcg/LdJOL0FMKPEujPDaS3C92Wni4hIJatITsShMzDZ3ae4+1pgEEHRv5i7f+bui8MfxwItE3k8IiKSWAnMiaRlhAZjFpGsUpE7stx9AJuumu/v7rPNrAnwvpn9XMHde4zpIiJSySqSE2GBv+RFgAFhdhQpr8C/T4xNnguMqEATRESkkiUwJ5KWESr0iEhWMUts/cTdZ4f/5pvZmwSV+Xlm1tzd54S3ZeWHi88EWpVYvSUwO5zespzpIiJSySqSE3FcEIi7kG9mBxN8iD8g7gaIiEilS2BOJC0jdOuWiGSVRI6Sb2a1zKxO0XvgcOAnYAhwVrjYWcDg8P0Q4GQzq2Zm2xAMuvxleHvXcjPbN3za1pkl1hERkUqU4KepbKzAX3qfZrsAA4E+7r5wsxsvIiJJl8CcSFpGqEePiGSVBD+0vCnwZvgk9DzgJXd/x8y+Al41s3OB6cAJAO4+3sxeBSYABcDF7l4YbutC4FmgBkGXTHXdFxFJgQTnxFdAu7C4P4vgyYunlt6ftQbeAM5w90kJ3buIiCRcAnMiaRmhQo+IZJXcBH6Ad/cpwAaPOAwr7YduZJ3bgdvLmf410ClxrRMRkc2R4JwoMLNLgHeBXODpsOh/QTj/ceCfQEPg0fDCQYG775W4VoiISCIlKieSmREq9IhIVknshVoREck0ic4Jdx8ODC8z7fES788DzkvwbkVEJEkSmRPJyggVekQkqyS4S76IiGQY5YSIiMQShZxQoUdEskoEzssiIpJCygkREYklCjmhQo+IZJWcKJyZRUQkZZQTIiISSxRyQoUeEckqETgvi4hICiknREQklijkhAo9IpJVcsxT3QQREUljygkREYklCjmhQo+IZJUoDJ4mIiKpo5wQEZFYopATKvSISFaJwHlZRERSSDkhIiKxRCEnVOgRkaySk+oGiIhIWlNOiIhILFHICRV6RCSrRKGrpYiIpI5yQkREYolCTqjQIyJZxSJRgxcRkVRRToiISCxRyAkVekQkq5il/4lZRERSRzkhIiKxRCEnVOgRkSwTgb6WIiKSQsoJERGJJf1zQoUeEckqFoETs4iIpI5yQkREYolCTqjQIyJZJv1PzCIikkrKCRERiSX9c0KFHhHJKlG4p1ZERFJHOSEiIrFEISdU6BGRrBKFUfJFRCR1lBMiIhJLFHJChR4RySpRuKdWRERSRzkhIiKxRCEnVOgRkSyT/hV4ERFJJeWEiIjEkv45oUKPiGQVs/SvwIuISOooJ0REJJYo5IQKPSKSZdL/xCwiIqmknBARkVjSPydU6BGRrBKFe2pFRCR1lBMiIhJLFHJChR4RySpGbqqbICIiaUw5ISIisUQhJ1ToEZGsEoV7akVEJHWUEyIiEksUckKFHhHJMul/YhYRkVRSToiISCzpnxMq9IhIVrEIPA5RRERSRzkhIiKxRCEnVOgRkSyT/hV4ERFJJeWEiIjEkv45oUKPiGQVs/SvwIuISOooJ0REJJYo5IQKPSKSVaLQ1VJERFJHOSEiIrFEISdU6BGRLJP+XS1FRCSVlBMiIhJL+ueECj0iklUsAidmERFJHeWEiIjEEoWcUKFHRLKKWfqfmEVEJHWUEyIiEksUckKFHhHJMul/T62IiKSSckJERGJJ/5xQoUdEskoUBk8TEZHUUU6IiEgsUcgJFXpEJKtEoauliIikjnJCRERiiUJOqNAjIlkm/SvwIiKSSsoJERGJJf1zQoUeEckqURglX0REUkc5ISIisUQhJ8zdU90GicHM+rn7gFS3Q1JPfwsiUh6dG6SI/hZEpDw6N0gR/S1kj/TvcyT9Ut0ASRv6WxCR8ujcIEX0tyAi5dG5QYrobyFLqNAjIiIiIiIiIpIhVOgREREREREREckQKvSkP91DKUX0tyAi5dG5QYrob0FEyqNzgxTR30KW0GDMIiIiIiIiIiIZQj16REREREREREQyhAo9IiIiIiIiIiIZQoWeNGVmPc3sFzObbGZXp7o9kjpm9rSZ5ZvZT6lui4ikD+WEFFFOiEh5lBNSRDmRfVToSUNmlgs8AvQCOgCnmFmH1LZKUuhZoGeqGyEi6UM5IWU8i3JCREpQTkgZz6KcyCoq9KSnzsBkd5/i7muBQUCfFLdJUsTdxwCLUt0OEUkrygkpppwQkXIoJ6SYciL7qNCTnloAM0r8PDOcJiIiAsoJERGJTTkhksVU6ElPVs40r/RWiIhIulJOiIhILMoJkSymQk96mgm0KvFzS2B2itoiIiLpRzkhIiKxKCdEspgKPenpK6CdmW1jZlWBk4EhKW6TiIikD+WEiIjEopwQyWIq9KQhdy8ALgHeBSYCr7r7+NS2SlLFzF4GPgd2NLOZZnZuqtskIqmlnJCSlBMiUpZyQkpSTmQfc9etmiIiIiIiIiIimUA9ekREREREREREMoQKPSIiIiIiIiIiGUKFHhERERERERGRDKFCj4iIiIiIiIhIhlChR0REREREREQkQ6jQI6WYWaGZfW9mP5nZ/8ys5hZs61kzOz58P9DMOsRYtpuZ7bcZ+5hqZo3KmV7bzJ4ws9/MbLyZjTGzfcJ5Kyq6HxERCSgnREQkFuWESOqp0CNlrXL33dy9E7AWuKDkTDPL3ZyNuvt57j4hxiLdgAqfmGMYCCwC2rl7R+BsYIMTuIiIVJhyQkREYlFOiKSYCj0Sy8fA9mF1/EMzewkYZ2a5ZnaPmX1lZj+a2fkAFnjYzCaY2TCgSdGGzOwjM9srfN/TzL41sx/MbKSZtSUIgMvD6v+BZtbYzF4P9/GVme0frtvQzN4zs+/M7AnAyjbazLYD9gGud/f1AO4+xd2HlVmudrj/b81snJn1CafXMrNhYft+MrOTwun/Co/tRzO7N8G/axGRKFJOKCdERGJRTignJAXyUt0ASU9mlgf0At4JJ3UGOrn772bWD1jq7nubWTXgUzN7D9gd2BHYGWgKTACeLrPdxsCTQNdwWw3cfZGZPQ6scPd7w+VeAh5w90/MrDXwLrATcCPwibvfYmZHAv3KaX5H4Ht3L9zEYa4G/uLuyyzorjnWzIYAPYHZ7n5k2JZ6ZtYA+AvQ3t3dzOrH9YsUEclQygnlhIhILMoJ5YSkjgo9UlYNM/s+fP8x8BRBF8gv3f33cPrhwC4W3i8L1APaAV2Bl8MT4mwzG1XO9vcFxhRty90XbaQdhwEdzIoL7HXNrE64j2PDdYeZ2eLNO0wgqN7fYWZdgfVAC4JAGQfca2Z3AW+7+8dhUK0GBoZXF97egv2KiESZckI5ISISi3JCOSEppkKPlLXK3XcrOSE8Oa4sOQm41N3fLbPcEYBvYvsWxzIQ3FbYxd1XldOWTa0/HtjVzHKKulpuxGlAY2BPd19nZlOB6u4+ycz2BI4A7jSz98KKf2fgUOBk4BLgkDiOQ0Qk0ygnlBMiIrEoJ5QTkmIao0c2x7vAhWZWBcDMdjCzWsAY4GQL7rltDhxczrqfAweZ2Tbhug3C6cuBOiWWe4/g5Ee43G7h2zEEJ1TMrBewVdkduPtvwNfAzRaeyc2sXdE9syXUA/LDk/LBQJtw2a2BP9z9ReBeYA8zqw3Uc/fhwGXAboiIyMYoJ5QTIiKxKCeUE5JE6tEjm2Mg0Bb4NjzxzQeOAd4kqEqPAyYBo8uu6O7zw3ty3zCzHCAf6A4MBV4LT56XAv2BR8zsR4K/0zEEA6zdDLxsZt+G25++kTaeB9wHTDazP4CFwD/KLPNfYKiZfQ18D/wcTt8ZuMfM1gPrgAsJQmOwmVUnuIpweTy/KBGRLKWcUE6IiMSinFBOSBKZezy93kREREREREREJN3p1i0RERERERERkQyhQo+IiIiIiIiISIZQoUdEREREREREJEOo0CMiIiIiIiIikiFU6BERERERERERyRAq9IiIiIiIiIiIZAgVekREREREREREMsT/A+ppsAN2fKiMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Test confusion_matrix')\n",
    "plot_confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db2cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
